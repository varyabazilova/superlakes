{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM 2 + NDWI Hybrid Lake Detection\n",
    "\n",
    "**Strategy:**\n",
    "1. Use NDWI to find candidate lake areas (fast, good recall)\n",
    "2. Use SAM 2 to get precise lake boundaries (accurate, handles complex shapes)\n",
    "3. Combine for automated, accurate lake detection\n",
    "\n",
    "**Advantages:**\n",
    "- No training needed\n",
    "- Precise boundaries\n",
    "- Handles your 10-pixel-wide lakes\n",
    "- Much simpler than DINOv3!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Test SAM 2 Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SAM 2 installation\n",
    "try:\n",
    "    import sam2\n",
    "    from sam2.build_sam import build_sam2\n",
    "    from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "    print(\"âœ… SAM 2 installed successfully!\")\nexcept ImportError as e:\n",
    "    print(f\"âŒ SAM 2 not installed: {e}\")\n",
    "    print(\"Please run: pip install git+https://github.com/facebookresearch/segment-anything-2.git\")\n",
    "\n",
    "# Other imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio.features import rasterize\n",
    "from scipy import ndimage\n",
    "from skimage import measure\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your Planet imagery and masks\n",
    "image_path = \"/Users/varyabazilova/Desktop/glacial_lakes/super_lakes/dinov3_tryout/test_data/2021-09-04_fcc_testclip2.tif\"\n",
    "mask_path = \"/Users/varyabazilova/Desktop/glacial_lakes/super_lakes/dinov3_tryout/test_data/lake_mask_testclip2.tif\"\n",
    "glacier_shp_path = \"/Users/varyabazilova/Desktop/glacial_lakes/super_lakes/dinov3_tryout/test_data/clip_by_glacier.shp\"\n",
    "\n",
    "# Load image (Planet 4-band: RGB + NIR)\n",
    "with rasterio.open(image_path) as src:\n",
    "    image = src.read()  # Shape: (channels, height, width)\n",
    "    image = np.transpose(image, (1, 2, 0))  # Change to (height, width, channels)\n",
    "    image_transform = src.transform\n",
    "    image_crs = src.crs\n",
    "\n",
    "# Load ground truth lake mask (for comparison)\n",
    "with rasterio.open(mask_path) as src:\n",
    "    ground_truth_lakes = src.read(1) > 0\n",
    "\n",
    "# Extract RGB and NIR\n",
    "rgb = image[:,:,:3].astype(np.uint8)\n",
    "nir = image[:,:,3]\n",
    "green = image[:,:,1]\n",
    "\n",
    "# Calculate NDWI\n",
    "ndwi = (green.astype(float) - nir.astype(float)) / (green.astype(float) + nir.astype(float) + 1e-8)\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"RGB range: {rgb.min()} - {rgb.max()}\")\n",
    "print(f\"NDWI range: {ndwi.min():.3f} - {ndwi.max():.3f}\")\n",
    "print(f\"Ground truth lakes: {ground_truth_lakes.sum():,} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load glacier mask\n",
    "glacier_gdf = gpd.read_file(glacier_shp_path)\n",
    "if glacier_gdf.crs != image_crs:\n",
    "    glacier_gdf = glacier_gdf.to_crs(image_crs)\n",
    "\n",
    "glacier_mask = rasterize(\n",
    "    [(geom, 1) for geom in glacier_gdf.geometry],\n",
    "    out_shape=image.shape[:2],\n",
    "    transform=image_transform,\n",
    "    fill=0\n",
    ").astype(bool)\n",
    "\n",
    "print(f\"Glacier area: {glacier_mask.sum():,} pixels ({glacier_mask.mean()*100:.1f}% of image)\")\n",
    "print(f\"Lakes in glacier: {(glacier_mask & ground_truth_lakes).sum():,} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# RGB image\n",
    "axes[0,0].imshow(rgb)\n",
    "axes[0,0].set_title('RGB Image')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "# NDWI\n",
    "ndwi_display = axes[0,1].imshow(ndwi, cmap='RdBu', vmin=-0.5, vmax=0.5)\n",
    "axes[0,1].set_title('NDWI (Blue=Water)')\n",
    "axes[0,1].axis('off')\n",
    "plt.colorbar(ndwi_display, ax=axes[0,1], shrink=0.8)\n",
    "\n",
    "# NDWI candidates (your working threshold)\n",
    "ndwi_candidates = (ndwi > 0.0) & glacier_mask\n",
    "axes[0,2].imshow(ndwi_candidates, cmap='Blues')\n",
    "axes[0,2].set_title(f'NDWI > 0.0 Candidates\\n({ndwi_candidates.sum():,} pixels)')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "# Glacier mask\n",
    "axes[1,0].imshow(glacier_mask, cmap='Greens')\n",
    "axes[1,0].set_title('Glacier Mask')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "# Ground truth lakes\n",
    "axes[1,1].imshow(ground_truth_lakes, cmap='Blues')\n",
    "axes[1,1].set_title('Ground Truth Lakes')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "# Overlay: RGB + NDWI candidates + ground truth\n",
    "axes[1,2].imshow(rgb)\n",
    "axes[1,2].imshow(ndwi_candidates, cmap='Reds', alpha=0.5)\n",
    "axes[1,2].contour(ground_truth_lakes, levels=[0.5], colors='blue', linewidths=2)\n",
    "axes[1,2].set_title('Overlay: NDWI (Red) + Truth (Blue)')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"NDWI candidate statistics:\")\n",
    "print(f\"  Total candidates: {ndwi_candidates.sum():,} pixels\")\n",
    "print(f\"  True positives: {(ndwi_candidates & ground_truth_lakes).sum():,} pixels\")\n",
    "print(f\"  False positives: {(ndwi_candidates & ~ground_truth_lakes).sum():,} pixels\")\n",
    "recall = (ndwi_candidates & ground_truth_lakes).sum() / ground_truth_lakes.sum() if ground_truth_lakes.sum() > 0 else 0\n",
    "print(f\"  NDWI recall: {recall:.1%} (how many real lakes it finds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize SAM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SAM 2\n",
    "print(\"Loading SAM 2 model...\")\n",
    "\n",
    "# Use smaller model for faster processing (you can upgrade to large later)\n",
    "sam2_checkpoint = \"./checkpoints/sam2_hiera_small.pt\"\n",
    "model_cfg = \"sam2_hiera_s.yaml\"\n",
    "\n",
    "# Try to load SAM 2\n",
    "try:\n",
    "    sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cpu\")  # Use CPU for now\n",
    "    sam2_predictor = SAM2ImagePredictor(sam2_model)\n",
    "    print(\"âœ… SAM 2 model loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading SAM 2: {e}\")\n",
    "    print(\"\\nTrying automatic model download...\")\n",
    "    \n",
    "    # Alternative: use default model (will auto-download)\n",
    "    try:\n",
    "        from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "        # This should auto-download model weights\n",
    "        sam2_model = build_sam2(\"sam2_hiera_l.yaml\", \"sam2_hiera_large.pt\", device=\"cpu\")\n",
    "        sam2_predictor = SAM2ImagePredictor(sam2_model)\n",
    "        print(\"âœ… SAM 2 model auto-downloaded and loaded!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"âŒ Auto-download also failed: {e2}\")\n",
    "        print(\"\\nPlease manually download SAM 2 weights from:\")\n",
    "        print(\"https://github.com/facebookresearch/segment-anything-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: SAM 2 + NDWI Hybrid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sam2_ndwi_hybrid_detection(rgb_image, ndwi, glacier_mask, sam2_predictor, \n",
    "                              ndwi_threshold=0.0, min_candidate_size=20):\n",
    "    \"\"\"\n",
    "    Hybrid SAM 2 + NDWI lake detection\n",
    "    \n",
    "    Steps:\n",
    "    1. Use NDWI to find candidate lake areas\n",
    "    2. Use SAM 2 to get precise boundaries for each candidate\n",
    "    3. Combine results\n",
    "    \"\"\"\n",
    "    print(f\"Running SAM 2 + NDWI hybrid detection...\")\n",
    "    \n",
    "    # Step 1: NDWI candidates (your working approach)\n",
    "    ndwi_candidates = (ndwi > ndwi_threshold) & glacier_mask\n",
    "    print(f\"NDWI found {ndwi_candidates.sum():,} candidate pixels\")\n",
    "    \n",
    "    # Step 2: Clean up candidates (remove tiny spots)\n",
    "    # Remove small isolated pixels\n",
    "    cleaned_candidates = ndimage.binary_opening(ndwi_candidates, structure=np.ones((3,3)))\n",
    "    # Remove very small connected components\n",
    "    labeled_candidates = measure.label(cleaned_candidates)\n",
    "    candidate_props = measure.regionprops(labeled_candidates)\n",
    "    \n",
    "    large_candidates = np.zeros_like(cleaned_candidates)\n",
    "    candidate_centers = []\n",
    "    \n",
    "    for prop in candidate_props:\n",
    "        if prop.area >= min_candidate_size:  # Keep reasonably sized candidates\n",
    "            # Add this candidate region\n",
    "            large_candidates[labeled_candidates == prop.label] = True\n",
    "            # Store centroid for SAM 2 prompting\n",
    "            candidate_centers.append([int(prop.centroid[1]), int(prop.centroid[0])])  # SAM wants [x, y]\n",
    "    \n",
    "    print(f\"Found {len(candidate_centers)} candidate regions for SAM 2 refinement\")\n",
    "    \n",
    "    if len(candidate_centers) == 0:\n",
    "        print(\"No candidates found - returning empty mask\")\n",
    "        return np.zeros_like(ndwi, dtype=bool), ndwi_candidates, []\n",
    "    \n",
    "    # Step 3: Set up SAM 2\n",
    "    sam2_predictor.set_image(rgb_image)\n",
    "    \n",
    "    # Step 4: Use SAM 2 to refine each candidate\n",
    "    final_mask = np.zeros_like(ndwi, dtype=bool)\n",
    "    sam_results = []\n",
    "    \n",
    "    print(f\"Running SAM 2 on {len(candidate_centers)} candidates...\")\n",
    "    \n",
    "    for i, center in enumerate(candidate_centers):\n",
    "        try:\n",
    "            # Use candidate center as prompt point\n",
    "            input_point = np.array([center])\n",
    "            input_label = np.array([1])  # 1 = foreground\n",
    "            \n",
    "            # Get SAM 2 prediction\n",
    "            masks, scores, logits = sam2_predictor.predict(\n",
    "                point_coords=input_point,\n",
    "                point_labels=input_label,\n",
    "                multimask_output=True\n",
    "            )\n",
    "            \n",
    "            # Choose best mask (highest score)\n",
    "            best_mask_idx = np.argmax(scores)\n",
    "            best_mask = masks[best_mask_idx]\n",
    "            best_score = scores[best_mask_idx]\n",
    "            \n",
    "            # Only keep if it's within glacier and reasonable quality\n",
    "            glacier_overlap = (best_mask & glacier_mask).sum() / best_mask.sum() if best_mask.sum() > 0 else 0\n",
    "            \n",
    "            if best_score > 0.5 and glacier_overlap > 0.7:  # Good quality and mostly on glacier\n",
    "                # Constrain to glacier area\n",
    "                constrained_mask = best_mask & glacier_mask\n",
    "                final_mask |= constrained_mask\n",
    "                \n",
    "                sam_results.append({\n",
    "                    'center': center,\n",
    "                    'mask': constrained_mask,\n",
    "                    'score': best_score,\n",
    "                    'glacier_overlap': glacier_overlap\n",
    "                })\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"  Processed {i + 1}/{len(candidate_centers)} candidates\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing candidate {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"SAM 2 refinement complete!\")\n",
    "    print(f\"Final result: {final_mask.sum():,} lake pixels\")\n",
    "    print(f\"Successful SAM predictions: {len(sam_results)}/{len(candidate_centers)}\")\n",
    "    \n",
    "    return final_mask, large_candidates, sam_results\n",
    "\n",
    "print(\"Hybrid detection function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run SAM 2 + NDWI Hybrid Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the hybrid detection\n",
    "if 'sam2_predictor' in locals():\n",
    "    print(\"Running SAM 2 + NDWI hybrid detection...\")\n",
    "    \n",
    "    hybrid_lakes, ndwi_candidates, sam_results = sam2_ndwi_hybrid_detection(\n",
    "        rgb, ndwi, glacier_mask, sam2_predictor,\n",
    "        ndwi_threshold=0.0,  # Your working threshold\n",
    "        min_candidate_size=20  # Minimum 20 pixels for candidate regions\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nHybrid detection results:\")\n",
    "    print(f\"  SAM 2 detected lakes: {hybrid_lakes.sum():,} pixels\")\n",
    "    print(f\"  Original NDWI candidates: {ndwi_candidates.sum():,} pixels\")\n",
    "    print(f\"  Ground truth lakes: {ground_truth_lakes.sum():,} pixels\")\n",
    "    \n",
    "    # Calculate accuracy metrics\n",
    "    if ground_truth_lakes.sum() > 0:\n",
    "        # SAM 2 hybrid metrics\n",
    "        hybrid_tp = (hybrid_lakes & ground_truth_lakes).sum()\n",
    "        hybrid_fp = (hybrid_lakes & ~ground_truth_lakes).sum()\n",
    "        hybrid_fn = (~hybrid_lakes & ground_truth_lakes).sum()\n",
    "        \n",
    "        hybrid_precision = hybrid_tp / (hybrid_tp + hybrid_fp) if (hybrid_tp + hybrid_fp) > 0 else 0\n",
    "        hybrid_recall = hybrid_tp / (hybrid_tp + hybrid_fn) if (hybrid_tp + hybrid_fn) > 0 else 0\n",
    "        hybrid_f1 = 2 * (hybrid_precision * hybrid_recall) / (hybrid_precision + hybrid_recall) if (hybrid_precision + hybrid_recall) > 0 else 0\n",
    "        \n",
    "        # NDWI-only metrics for comparison\n",
    "        ndwi_tp = (ndwi_candidates & ground_truth_lakes).sum()\n",
    "        ndwi_fp = (ndwi_candidates & ~ground_truth_lakes).sum()\n",
    "        ndwi_fn = (~ndwi_candidates & ground_truth_lakes).sum()\n",
    "        \n",
    "        ndwi_precision = ndwi_tp / (ndwi_tp + ndwi_fp) if (ndwi_tp + ndwi_fp) > 0 else 0\n",
    "        ndwi_recall = ndwi_tp / (ndwi_tp + ndwi_fn) if (ndwi_tp + ndwi_fn) > 0 else 0\n",
    "        ndwi_f1 = 2 * (ndwi_precision * ndwi_recall) / (ndwi_precision + ndwi_recall) if (ndwi_precision + ndwi_recall) > 0 else 0\n",
    "        \n",
    "        print(f\"\\nAccuracy Comparison:\")\n",
    "        print(f\"Method        Precision  Recall   F1-Score\")\n",
    "        print(f\"NDWI only     {ndwi_precision:.3f}     {ndwi_recall:.3f}   {ndwi_f1:.3f}\")\n",
    "        print(f\"SAM2+NDWI     {hybrid_precision:.3f}     {hybrid_recall:.3f}   {hybrid_f1:.3f}\")\n",
    "        \n",
    "        if hybrid_f1 > ndwi_f1:\n",
    "            print(f\"\\nâœ… SAM 2 hybrid approach improved F1-score by {hybrid_f1 - ndwi_f1:.3f}!\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸  NDWI alone performed better. SAM 2 may be over-segmenting.\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ SAM 2 predictor not loaded. Please fix the SAM 2 installation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the hybrid detection results\n",
    "if 'hybrid_lakes' in locals():\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Original RGB\n",
    "    axes[0,0].imshow(rgb)\n",
    "    axes[0,0].set_title('Original RGB Image')\n",
    "    axes[0,0].axis('off')\n",
    "    \n",
    "    # NDWI candidates\n",
    "    axes[0,1].imshow(rgb)\n",
    "    axes[0,1].imshow(ndwi_candidates, cmap='Reds', alpha=0.6)\n",
    "    axes[0,1].set_title('NDWI Candidates (Red)')\n",
    "    axes[0,1].axis('off')\n",
    "    \n",
    "    # SAM 2 + NDWI result\n",
    "    axes[0,2].imshow(rgb)\n",
    "    axes[0,2].imshow(hybrid_lakes, cmap='Blues', alpha=0.6)\n",
    "    axes[0,2].set_title('SAM 2 + NDWI Result (Blue)')\n",
    "    axes[0,2].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[1,0].imshow(rgb)\n",
    "    axes[1,0].imshow(ground_truth_lakes, cmap='Greens', alpha=0.6)\n",
    "    axes[1,0].set_title('Ground Truth (Green)')\n",
    "    axes[1,0].axis('off')\n",
    "    \n",
    "    # Comparison: SAM vs Truth\n",
    "    axes[1,1].imshow(rgb)\n",
    "    axes[1,1].imshow(hybrid_lakes, cmap='Blues', alpha=0.4, label='SAM Prediction')\n",
    "    axes[1,1].contour(ground_truth_lakes, levels=[0.5], colors='green', linewidths=2, alpha=0.8)\n",
    "    axes[1,1].set_title('SAM Prediction (Blue) vs Truth (Green)')\n",
    "    axes[1,1].axis('off')\n",
    "    \n",
    "    # Error analysis\n",
    "    true_positives = hybrid_lakes & ground_truth_lakes\n",
    "    false_positives = hybrid_lakes & ~ground_truth_lakes\n",
    "    false_negatives = ~hybrid_lakes & ground_truth_lakes\n",
    "    \n",
    "    error_display = np.zeros((*rgb.shape[:2], 3), dtype=np.uint8)\n",
    "    error_display[true_positives] = [0, 255, 0]    # Green: correct\n",
    "    error_display[false_positives] = [255, 0, 0]   # Red: false positive\n",
    "    error_display[false_negatives] = [0, 0, 255]   # Blue: missed\n",
    "    \n",
    "    axes[1,2].imshow(rgb)\n",
    "    axes[1,2].imshow(error_display, alpha=0.6)\n",
    "    axes[1,2].set_title('Error Analysis\\nGreen=Correct, Red=False+, Blue=Missed')\n",
    "    axes[1,2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show some individual SAM results\n",
    "    if len(sam_results) > 0:\n",
    "        print(f\"\\nShowing individual SAM 2 results (first 6):\")\n",
    "        n_show = min(6, len(sam_results))\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i in range(n_show):\n",
    "            result = sam_results[i]\n",
    "            \n",
    "            # Create crop around this result for better visibility\n",
    "            center = result['center']\n",
    "            crop_size = 100\n",
    "            y_start = max(0, center[1] - crop_size)\n",
    "            y_end = min(rgb.shape[0], center[1] + crop_size)\n",
    "            x_start = max(0, center[0] - crop_size)\n",
    "            x_end = min(rgb.shape[1], center[0] + crop_size)\n",
    "            \n",
    "            crop_rgb = rgb[y_start:y_end, x_start:x_end]\n",
    "            crop_mask = result['mask'][y_start:y_end, x_start:x_end]\n",
    "            \n",
    "            axes[i].imshow(crop_rgb)\n",
    "            axes[i].imshow(crop_mask, cmap='Blues', alpha=0.6)\n",
    "            axes[i].plot(center[0] - x_start, center[1] - y_start, 'r*', markersize=10)\n",
    "            axes[i].set_title(f'SAM Result {i+1}\\nScore: {result[\"score\"]:.2f}')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\nelse:\n",
    "    print(\"No results to visualize. Please run the detection first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Results and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for further analysis\n",
    "if 'hybrid_lakes' in locals():\n",
    "    \n",
    "    # Save as GeoTIFF\n",
    "    from rasterio.transform import from_bounds\n",
    "    \n",
    "    output_path = '/Users/varyabazilova/Desktop/glacial_lakes/super_lakes/sam2_hybrid_lakes.tif'\n",
    "    \n",
    "    with rasterio.open(\n",
    "        output_path, 'w',\n",
    "        driver='GTiff',\n",
    "        height=hybrid_lakes.shape[0],\n",
    "        width=hybrid_lakes.shape[1],\n",
    "        count=1,\n",
    "        dtype=np.uint8,\n",
    "        crs=image_crs,\n",
    "        transform=image_transform\n",
    "    ) as dst:\n",
    "        dst.write(hybrid_lakes.astype(np.uint8), 1)\n",
    "    \n",
    "    print(f\"Results saved to: {output_path}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    lake_area_km2 = hybrid_lakes.sum() * 9 / 1_000_000  # 3m pixels\n",
    "    print(f\"\\n=== SAM 2 + NDWI Hybrid Detection Summary ===\")\n",
    "    print(f\"Total detected lake area: {lake_area_km2:.3f} kmÂ²\")\n",
    "    print(f\"Number of lake pixels: {hybrid_lakes.sum():,}\")\n",
    "    print(f\"Percentage of glacier area: {hybrid_lakes.sum() / glacier_mask.sum() * 100:.2f}%\")\n",
    "    \n",
    "    if 'hybrid_f1' in locals():\n",
    "        print(f\"\\nAccuracy vs Ground Truth:\")\n",
    "        print(f\"  Precision: {hybrid_precision:.3f}\")\n",
    "        print(f\"  Recall: {hybrid_recall:.3f}\")\n",
    "        print(f\"  F1-Score: {hybrid_f1:.3f}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ SAM 2 + NDWI hybrid detection complete!\")\n",
    "    \n",
    "    print(f\"\\nNext steps:\")\n",
    "    print(f\"  1. Fine-tune parameters (NDWI threshold, min_candidate_size)\")\n",
    "    print(f\"  2. Apply to time series data\")\n",
    "    print(f\"  3. Compare with your existing NDWI-only approach\")\n",
    "    print(f\"  4. Scale up to larger model (sam2_hiera_large) for better accuracy\")\n",
    "\nelse:\n",
    "    print(\"No results to save. Please run the detection first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {\n   \"display_name\": \"superlakes\",\n   \"language\": \"python\",\n   \"name\": \"superlakes\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.11.13\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}
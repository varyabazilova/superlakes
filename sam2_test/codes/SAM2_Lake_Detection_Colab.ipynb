{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title_cell"
   },
   "source": [
    "# SAM 2 Lake Detection with Ground Truth Tuning - Google Colab Version\n",
    "\n",
    "This notebook systematically tunes SAM 2 parameters for glacial lake detection using ground truth data.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Upload your images and ground truth mask to Google Drive\n",
    "- Enable GPU runtime (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
    "\n",
    "**Workflow:**\n",
    "1. Mount Google Drive and setup environment\n",
    "2. Load satellite image (RGB/FCC/NDWI) and ground truth\n",
    "3. Test different SAM 2 parameter combinations\n",
    "4. Find optimal parameters using IoU, precision, recall\n",
    "5. Generate final results with best configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_section"
   },
   "source": [
    "## üîß Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_colab"
   },
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üîµ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üü° Running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"‚úÖ Google Drive mounted at /content/drive\")\n",
    "    \n",
    "    # List Drive contents to help you find your files\n",
    "    import os\n",
    "    print(\"\\nüìÅ Your Google Drive contents:\")\n",
    "    drive_path = \"/content/drive/MyDrive\"\n",
    "    if os.path.exists(drive_path):\n",
    "        for item in os.listdir(drive_path)[:10]:  # Show first 10 items\n",
    "            print(f\"  üìÇ {item}\")\n",
    "        if len(os.listdir(drive_path)) > 10:\n",
    "            print(f\"  ... and {len(os.listdir(drive_path)) - 10} more items\")\n",
    "    else:\n",
    "        print(\"  Drive path not found. Check mounting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(\"‚úÖ GPU is ready for SAM 2!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected!\")\n",
    "    print(\"Go to Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")\n",
    "    print(\"Then restart the runtime.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_packages"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"üì¶ Installing required packages...\")\n",
    "\n",
    "# Core packages\n",
    "!pip install opencv-python matplotlib scikit-learn pandas\n",
    "!pip install rasterio geopandas\n",
    "\n",
    "# SAM 2\n",
    "!pip install 'git+https://github.com/facebookresearch/sam2.git'\n",
    "\n",
    "# TorchGeo (optional, for advanced geospatial processing)\n",
    "!pip install torchgeo\n",
    "\n",
    "print(\"‚úÖ Package installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_sam2_model"
   },
   "outputs": [],
   "source": [
    "# Download SAM 2 model weights\n",
    "import os\n",
    "\n",
    "model_dir = \"/content/sam2_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "model_path = f\"{model_dir}/sam2.1_hiera_large.pt\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"üì• Downloading SAM 2 model (856MB)...\")\n",
    "    !wget -P {model_dir} https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\n",
    "    print(\"‚úÖ SAM 2 model downloaded!\")\n",
    "else:\n",
    "    print(\"‚úÖ SAM 2 model already exists!\")\n",
    "\n",
    "# Also download config files\n",
    "config_dir = \"/content/sam2_configs\"\n",
    "os.makedirs(config_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(f\"{config_dir}/sam2.1_hiera_l.yaml\"):\n",
    "    print(\"üì• Downloading SAM 2 config files...\")\n",
    "    !wget -P {config_dir} https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2.1/sam2.1_hiera_l.yaml\n",
    "    !wget -P {config_dir} https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2.1/sam2.1_hiera_b+.yaml\n",
    "    !wget -P {config_dir} https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2.1/sam2.1_hiera_s.yaml\n",
    "    print(\"‚úÖ Config files downloaded!\")\n",
    "else:\n",
    "    print(\"‚úÖ Config files already exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_section"
   },
   "source": [
    "## üìö Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Geospatial libraries\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "\n",
    "# PyTorch and SAM 2\n",
    "import torch\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "# TorchGeo (if needed)\n",
    "try:\n",
    "    import torchgeo\n",
    "    print(f\"TorchGeo version: {torchgeo.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"TorchGeo not available (optional)\")\n",
    "\n",
    "print(f\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config_section"
   },
   "source": [
    "## ‚öôÔ∏è Configuration - UPDATE YOUR FILE PATHS\n",
    "\n",
    "**Important:** Update the paths below to point to your files in Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "configuration"
   },
   "outputs": [],
   "source": "# =============================================================================\n# üö® UPDATE THESE PATHS TO YOUR GOOGLE DRIVE FILES\n# =============================================================================\n\n# Base path to your data in Google Drive\n# Example: if your files are in \"My Drive/lake_data/\", use:\nDRIVE_DATA_PATH = \"/content/drive/MyDrive/superlakes/\"  # UPDATE THIS\n\n# Choose your input image type\nIMAGE_TYPE = \"RGB\"  # Options: \"RGB\", \"FCC\", \"NDWI\" - RGB often works best with SAM 2!\n\n# Image file paths (relative to DRIVE_DATA_PATH)\nIMAGE_FILES = {\n    \"RGB\": \"2021-09-04_rgb_testclip_sam2.tif\",   # True color RGB (often works best!)\n    \"FCC\": \"2021-09-04_fcc_testclip.tif\",       # False Color Composite\n    \"NDWI\": \"2021-09-04_fndwi_clip_sam.tif\"     # NDWI single band\n}\n\n# Ground truth file (binary mask: 1=lake, 0=not lake)\nGROUND_TRUTH_FILE = \"lake_mask_testclip.tif\"  # UPDATE THIS\n\n# SAM 2 model configuration\nSAM2_CONFIG = {\n    \"checkpoint\": \"/content/sam2_models/sam2.1_hiera_large.pt\",\n    \"config\": \"/content/sam2_configs/sam2.1_hiera_l.yaml\"\n}\n\n# =============================================================================\n\n# Construct full paths\nIMAGE_PATH = os.path.join(DRIVE_DATA_PATH, IMAGE_FILES[IMAGE_TYPE])\nGROUND_TRUTH_PATH = os.path.join(DRIVE_DATA_PATH, GROUND_TRUTH_FILE)\n\nprint(f\"üéØ Configuration:\")\nprint(f\"   Image type: {IMAGE_TYPE} ‚Üê RGB often works best with SAM 2!\")\nprint(f\"   Image path: {IMAGE_PATH}\")\nprint(f\"   Ground truth: {GROUND_TRUTH_PATH}\")\nprint(f\"   SAM 2 model: {SAM2_CONFIG['checkpoint']}\")\n\n# Verify files exist\nprint(f\"\\nüìÅ File verification:\")\nprint(f\"   Image exists: {'‚úÖ' if os.path.exists(IMAGE_PATH) else '‚ùå'}\")\nprint(f\"   Ground truth exists: {'‚úÖ' if os.path.exists(GROUND_TRUTH_PATH) else '‚ùå'}\")\nprint(f\"   SAM 2 model exists: {'‚úÖ' if os.path.exists(SAM2_CONFIG['checkpoint']) else '‚ùå'}\")\n\nif not os.path.exists(DRIVE_DATA_PATH):\n    print(f\"\\n‚ö†Ô∏è Data directory not found: {DRIVE_DATA_PATH}\")\n    print(\"Please update DRIVE_DATA_PATH to your actual Google Drive folder.\")\n\nprint(f\"\\nüí° Tip: Try different image types by changing IMAGE_TYPE above!\")\nprint(f\"   RGB: Often best for SAM 2 (trained on natural images)\")\nprint(f\"   FCC: Good for vegetation/water contrast\") \nprint(f\"   NDWI: Emphasizes water but may confuse SAM 2\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "device_section"
   },
   "source": [
    "## üñ•Ô∏è Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "device_setup"
   },
   "outputs": [],
   "source": [
    "# Set up compute device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"üöÄ Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Optimize for GPU\n",
    "    torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "    if torch.cuda.get_device_properties(0).major >= 8:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        print(\"‚úÖ TensorFloat-32 optimization enabled\")\n",
    "        \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"üçé Using Apple Metal Performance Shaders (MPS)\")\n",
    "    print(\"Note: MPS support is experimental and may give different results\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"üíª Using CPU (will be slower)\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utils_section"
   },
   "source": [
    "## üõ†Ô∏è Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utility_functions"
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def show_anns(anns, borders=True):\n",
    "    \"\"\"Visualize SAM 2 annotations with random colors\"\"\"\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    \n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:, :, 3] = 0\n",
    "    \n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.5]])\n",
    "        img[m] = color_mask\n",
    "        \n",
    "        if borders:\n",
    "            import cv2\n",
    "            contours, _ = cv2.findContours(m.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "            cv2.drawContours(img, contours, -1, (0, 0, 1, 0.4), thickness=1)\n",
    "\n",
    "    ax.imshow(img)\n",
    "\n",
    "def load_image_data(image_path, image_type):\n",
    "    \"\"\"Load and prepare image data based on type\"\"\"\n",
    "    print(f\"Loading {image_type} image from: {image_path}\")\n",
    "    \n",
    "    if image_type == \"FCC\" or image_type == \"RGB\":\n",
    "        # False Color Composite or RGB\n",
    "        image = Image.open(image_path)\n",
    "        image = np.array(image.convert(\"RGB\"))\n",
    "        \n",
    "    elif image_type == \"NDWI\":\n",
    "        # NDWI converted to 3-channel\n",
    "        with rasterio.open(image_path) as src:\n",
    "            ndwi = src.read(1)\n",
    "        \n",
    "        # Normalize NDWI from [-1, 1] to [0, 255]\n",
    "        ndwi_normalized = ((ndwi + 1) / 2 * 255).astype(np.uint8)\n",
    "        \n",
    "        # Create 3-channel array\n",
    "        image = np.stack([ndwi_normalized, ndwi_normalized, ndwi_normalized], axis=-1)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown image type: {image_type}\")\n",
    "    \n",
    "    return image\n",
    "\n",
    "def calculate_metrics(ground_truth, predicted_mask):\n",
    "    \"\"\"Calculate IoU, precision, recall, F1 score\"\"\"\n",
    "    gt_flat = ground_truth.flatten()\n",
    "    pred_flat = predicted_mask.flatten()\n",
    "    \n",
    "    iou = jaccard_score(gt_flat, pred_flat)\n",
    "    precision = precision_score(gt_flat, pred_flat, zero_division=0)\n",
    "    recall = recall_score(gt_flat, pred_flat, zero_division=0)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'iou': iou,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Utility functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load_data_section"
   },
   "source": [
    "## üìÇ Load Image and Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_image"
   },
   "outputs": [],
   "source": [
    "# Load satellite image\n",
    "try:\n",
    "    image = load_image_data(IMAGE_PATH, IMAGE_TYPE)\n",
    "    print(f\"‚úÖ Image loaded successfully!\")\n",
    "    print(f\"   Shape: {image.shape}\")\n",
    "    print(f\"   Data type: {image.dtype}\")\n",
    "    print(f\"   Value range: {image.min()} - {image.max()}\")\n",
    "    \n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'{IMAGE_TYPE} Satellite Image\\nShape: {image.shape}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    IMAGE_LOADED = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading image: {e}\")\n",
    "    print(f\"Check your image path: {IMAGE_PATH}\")\n",
    "    IMAGE_LOADED = False\n",
    "    image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_ground_truth"
   },
   "outputs": [],
   "source": [
    "# Load ground truth lake mask\n",
    "try:\n",
    "    with rasterio.open(GROUND_TRUTH_PATH) as src:\n",
    "        ground_truth = src.read(1).astype(bool)\n",
    "    \n",
    "    print(f\"‚úÖ Ground truth loaded successfully!\")\n",
    "    print(f\"   Shape: {ground_truth.shape}\")\n",
    "    print(f\"   Lake pixels: {ground_truth.sum():,} ({ground_truth.mean()*100:.2f}% of image)\")\n",
    "    \n",
    "    # Check dimension compatibility\n",
    "    if IMAGE_LOADED and ground_truth.shape != image.shape[:2]:\n",
    "        print(f\"‚ö†Ô∏è WARNING: Dimension mismatch!\")\n",
    "        print(f\"   Image: {image.shape[:2]}\")\n",
    "        print(f\"   Ground truth: {ground_truth.shape}\")\n",
    "        print(\"   Consider resizing or checking coordinate systems.\")\n",
    "    elif IMAGE_LOADED:\n",
    "        print(\"‚úÖ Image and ground truth dimensions match!\")\n",
    "    \n",
    "    # Visualize ground truth overlay\n",
    "    if IMAGE_LOADED:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(image)\n",
    "        axes[0].set_title(f'{IMAGE_TYPE} Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Image with ground truth overlay\n",
    "        axes[1].imshow(image)\n",
    "        axes[1].imshow(ground_truth, alpha=0.6, cmap='Blues')\n",
    "        axes[1].set_title(f'Ground Truth Lakes Overlay\\n{ground_truth.sum():,} lake pixels')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    GROUND_TRUTH_LOADED = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading ground truth: {e}\")\n",
    "    print(f\"Check your ground truth path: {GROUND_TRUTH_PATH}\")\n",
    "    print(\"Will proceed without parameter tuning.\")\n",
    "    GROUND_TRUTH_LOADED = False\n",
    "    ground_truth = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sam2_init_section"
   },
   "source": [
    "## ü§ñ Initialize SAM 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "initialize_sam2"
   },
   "outputs": [],
   "source": "# Initialize SAM 2 model\nif IMAGE_LOADED:\n    try:\n        print(\"ü§ñ Loading SAM 2 model...\")\n        \n        # Use relative config path like in the example notebooks\n        # This works because build_sam2 looks for configs relative to the sam2 package\n        model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n        \n        print(f\"   Config: {model_cfg} (relative path)\")\n        print(f\"   Checkpoint: {SAM2_CONFIG['checkpoint']}\")\n        \n        # Build SAM 2 model using relative config path (like example notebooks)\n        sam2_model = build_sam2(\n            model_cfg,\n            SAM2_CONFIG['checkpoint'], \n            device=device, \n            apply_postprocessing=False\n        )\n        \n        print(\"‚úÖ SAM 2 model loaded successfully!\")\n        print(f\"   Model device: {next(sam2_model.parameters()).device}\")\n        \n        SAM2_LOADED = True\n        \n    except Exception as e:\n        print(f\"‚ùå Error loading SAM 2: {e}\")\n        print(\"Make sure SAM 2 was installed correctly with: pip install 'git+https://github.com/facebookresearch/sam2.git'\")\n        SAM2_LOADED = False\n        sam2_model = None\nelse:\n    print(\"‚è∏Ô∏è Skipping SAM 2 initialization (no image loaded)\")\n    SAM2_LOADED = False\n    sam2_model = None"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_test_section"
   },
   "source": [
    "## üß™ Quick Test with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "quick_test"
   },
   "outputs": [],
   "source": "# Quick test with default SAM 2 parameters\nif SAM2_LOADED:\n    print(\"üß™ Running quick test with default parameters...\")\n    \n    # Create default mask generator\n    default_generator = SAM2AutomaticMaskGenerator(sam2_model)\n    \n    # Generate masks\n    print(\"   Generating masks... (this may take a minute)\")\n    default_masks = default_generator.generate(image)\n    \n    print(f\"‚úÖ Default configuration generated {len(default_masks)} masks\")\n    \n    # Quick evaluation if ground truth is available\n    if GROUND_TRUTH_LOADED:\n        # Combine masks\n        combined_mask = np.zeros_like(ground_truth, dtype=bool)\n        for mask in default_masks:\n            combined_mask |= mask['segmentation']\n        \n        # Calculate metrics\n        default_metrics = calculate_metrics(ground_truth, combined_mask)\n        print(f\"   Default IoU: {default_metrics['iou']:.3f}\")\n        print(f\"   Default Precision: {default_metrics['precision']:.3f}\")\n        print(f\"   Default Recall: {default_metrics['recall']:.3f}\")\n        print(f\"   Default F1: {default_metrics['f1']:.3f}\")\n    \n    # Visualize result\n    plt.figure(figsize=(16, 16))\n    plt.imshow(image)\n    show_anns(default_masks)\n    plt.title(f'Default SAM 2 Result\\n{len(default_masks)} masks detected')\n    plt.axis('off')\n    plt.show()\n    \n    DEFAULT_TEST_DONE = True\n    \nelse:\n    print(\"‚è∏Ô∏è Skipping default test (SAM 2 not loaded)\")\n    DEFAULT_TEST_DONE = False\n    default_masks = []\n    default_metrics = {}"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "param_tuning_section"
   },
   "source": "# Detailed comparison: Default SAM 2 vs Ground Truth\nif DEFAULT_TEST_DONE and GROUND_TRUTH_LOADED:\n    print(\"üìä Creating detailed comparison of default SAM 2 vs ground truth...\")\n    \n    # Combine default masks into binary array\n    default_combined = np.zeros_like(ground_truth, dtype=bool)\n    for mask in default_masks:\n        default_combined |= mask['segmentation']\n    \n    # Create side-by-side comparison\n    fig, axes = plt.subplots(1, 2, figsize=(24, 12))\n    \n    # Left panel: Ground Truth\n    axes[0].imshow(image)\n    axes[0].imshow(ground_truth, alpha=0.7, cmap='Blues')\n    axes[0].set_title(f'Ground Truth Lakes\\n{ground_truth.sum():,} pixels ({ground_truth.mean()*100:.1f}% of image)', \n                     fontsize=14, fontweight='bold')\n    axes[0].axis('off')\n    \n    # Right panel: Default SAM 2 Result\n    axes[1].imshow(image)\n    axes[1].imshow(default_combined, alpha=0.7, cmap='Reds')\n    axes[1].set_title(f'Default SAM 2 Detection\\n{default_combined.sum():,} pixels ({default_combined.mean()*100:.1f}% of image)', \n                     fontsize=14, fontweight='bold')\n    axes[1].axis('off')\n    \n    # Add performance metrics as text\n    fig.suptitle(f'Default SAM 2 Performance: IoU={default_metrics[\"iou\"]:.3f}, Precision={default_metrics[\"precision\"]:.3f}, Recall={default_metrics[\"recall\"]:.3f}, F1={default_metrics[\"f1\"]:.3f}', \n                 fontsize=16, fontweight='bold', y=0.02)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Create detailed pixel-level analysis\n    print(\"\\nüîç Detailed pixel-level analysis:\")\n    \n    # Calculate pixel categories\n    true_positive = (ground_truth & default_combined).sum()\n    false_positive = (~ground_truth & default_combined).sum()\n    false_negative = (ground_truth & ~default_combined).sum()\n    true_negative = (~ground_truth & ~default_combined).sum()\n    \n    total_pixels = ground_truth.size\n    \n    print(f\"   ‚úÖ True Positives (correctly detected lakes): {true_positive:,} pixels\")\n    print(f\"   ‚ùå False Positives (incorrectly detected as lakes): {false_positive:,} pixels\")\n    print(f\"   ‚≠ï False Negatives (missed lake pixels): {false_negative:,} pixels\")\n    print(f\"   ‚úÖ True Negatives (correctly identified non-lakes): {true_negative:,} pixels\")\n    \n    print(f\"\\nüìà Analysis:\")\n    if false_positive > false_negative:\n        print(f\"   üî¥ SAM 2 is over-detecting (too many false positives)\")\n        print(f\"   üí° Suggestion: Increase quality thresholds or minimum area\")\n    elif false_negative > false_positive:\n        print(f\"   üîµ SAM 2 is under-detecting (missing lakes)\")\n        print(f\"   üí° Suggestion: Decrease thresholds or increase sampling density\")\n    else:\n        print(f\"   ‚öñÔ∏è Balanced detection errors\")\n    \n    # Show overlap visualization\n    fig, ax = plt.subplots(1, 1, figsize=(16, 12))\n    \n    # Create color-coded comparison\n    comparison = np.zeros((*ground_truth.shape, 3), dtype=np.uint8)\n    comparison[ground_truth & default_combined] = [0, 255, 0]        # True positive = Green\n    comparison[~ground_truth & default_combined] = [255, 0, 0]       # False positive = Red  \n    comparison[ground_truth & ~default_combined] = [0, 0, 255]       # False negative = Blue\n    \n    ax.imshow(image)\n    ax.imshow(comparison, alpha=0.6)\n    ax.set_title('Pixel-Level Comparison\\nüü¢ Correct Detection  üî¥ False Positives  üîµ Missed Lakes', \n                fontsize=14, fontweight='bold')\n    ax.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\nüéØ Summary: Default SAM 2 detects {default_metrics['recall']*100:.1f}% of your lakes but generates {false_positive:,} false positive pixels\")\n    \nelse:\n    print(\"‚è∏Ô∏è Skipping detailed comparison (default test or ground truth not available)\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Define parameter combinations to test\nif SAM2_LOADED and GROUND_TRUTH_LOADED:\n    print(\"üéØ Setting up parameter tuning experiments...\")\n    \n    param_configs = [\n        # Baseline: Default configuration for comparison\n        {\"points_per_side\": 32, \"pred_iou_thresh\": 0.88, \"min_mask_region_area\": 100, \"stability_score_thresh\": 0.95, \"name\": \"default\"},\n        \n        # SMALL LAKE FOCUSED CONFIGURATIONS\n        # Reduce minimum area to catch small lakes\n        {\"points_per_side\": 32, \"pred_iou_thresh\": 0.88, \"min_mask_region_area\": 25, \"stability_score_thresh\": 0.95, \"name\": \"small_lakes_v1\"},\n        {\"points_per_side\": 32, \"pred_iou_thresh\": 0.88, \"min_mask_region_area\": 10, \"stability_score_thresh\": 0.95, \"name\": \"tiny_lakes_v1\"},\n        {\"points_per_side\": 32, \"pred_iou_thresh\": 0.88, \"min_mask_region_area\": 5, \"stability_score_thresh\": 0.95, \"name\": \"micro_lakes\"},\n        \n        # Increase sampling density for small features\n        {\"points_per_side\": 48, \"pred_iou_thresh\": 0.88, \"min_mask_region_area\": 25, \"stability_score_thresh\": 0.95, \"name\": \"dense_small_lakes\"},\n        {\"points_per_side\": 64, \"pred_iou_thresh\": 0.88, \"min_mask_region_area\": 25, \"stability_score_thresh\": 0.95, \"name\": \"very_dense_small\"},\n        {\"points_per_side\": 80, \"pred_iou_thresh\": 0.88, \"min_mask_region_area\": 15, \"stability_score_thresh\": 0.95, \"name\": \"ultra_dense_small\"},\n        \n        # Relax quality thresholds while keeping small area detection\n        {\"points_per_side\": 48, \"pred_iou_thresh\": 0.8, \"min_mask_region_area\": 20, \"stability_score_thresh\": 0.9, \"name\": \"relaxed_small_v1\"},\n        {\"points_per_side\": 64, \"pred_iou_thresh\": 0.75, \"min_mask_region_area\": 15, \"stability_score_thresh\": 0.88, \"name\": \"relaxed_small_v2\"},\n        {\"points_per_side\": 48, \"pred_iou_thresh\": 0.82, \"min_mask_region_area\": 30, \"stability_score_thresh\": 0.92, \"name\": \"balanced_small\"},\n        \n        # MULTI-SCALE APPROACHES\n        # Try to get both small and large lakes\n        {\"points_per_side\": 40, \"pred_iou_thresh\": 0.85, \"min_mask_region_area\": 20, \"stability_score_thresh\": 0.93, \"name\": \"multi_scale_v1\"},\n        {\"points_per_side\": 56, \"pred_iou_thresh\": 0.83, \"min_mask_region_area\": 35, \"stability_score_thresh\": 0.91, \"name\": \"multi_scale_v2\"},\n        \n        # AGGRESSIVE DETECTION (may have more false positives but catch more lakes)\n        {\"points_per_side\": 64, \"pred_iou_thresh\": 0.7, \"min_mask_region_area\": 10, \"stability_score_thresh\": 0.85, \"name\": \"aggressive_detection\"},\n        {\"points_per_side\": 48, \"pred_iou_thresh\": 0.75, \"min_mask_region_area\": 15, \"stability_score_thresh\": 0.87, \"name\": \"moderate_aggressive\"},\n        \n        # FINE-TUNED VARIANTS (based on default but optimized for small lakes)\n        {\"points_per_side\": 40, \"pred_iou_thresh\": 0.86, \"min_mask_region_area\": 20, \"stability_score_thresh\": 0.94, \"name\": \"default_plus_small\"},\n        {\"points_per_side\": 36, \"pred_iou_thresh\": 0.84, \"min_mask_region_area\": 40, \"stability_score_thresh\": 0.93, \"name\": \"slightly_relaxed\"},\n    ]\n    \n    print(f\"üìã Will test {len(param_configs)} parameter combinations:\")\n    print(\"üéØ Focus: Detect small lakes while maintaining good performance on larger ones\")\n    print(\"\\nConfiguration types:\")\n    print(\"  üîµ Default: Baseline for comparison\")\n    print(\"  üü¢ Small lake focused: Lower min area, higher sampling\")\n    print(\"  üü° Multi-scale: Balance small and large lake detection\") \n    print(\"  üü† Aggressive: Lower thresholds to catch more lakes\")\n    print(\"  üü£ Fine-tuned: Modest improvements over default\")\n    print()\n    \n    for i, config in enumerate(param_configs, 1):\n        category = \"üîµ\" if \"default\" in config['name'] else \\\n                  \"üü¢\" if \"small\" in config['name'] or \"tiny\" in config['name'] or \"micro\" in config['name'] else \\\n                  \"üü°\" if \"multi\" in config['name'] else \\\n                  \"üü†\" if \"aggressive\" in config['name'] else \"üü£\"\n        print(f\"   {i:2d}. {category} {config['name']}\")\n    \n    TUNING_READY = True\n    \nelse:\n    print(\"‚è∏Ô∏è Skipping parameter tuning setup\")\n    if not SAM2_LOADED:\n        print(\"   Reason: SAM 2 not loaded\")\n    if not GROUND_TRUTH_LOADED:\n        print(\"   Reason: Ground truth not loaded\")\n    \n    TUNING_READY = False\n    param_configs = []",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_parameter_tuning"
   },
   "outputs": [],
   "source": [
    "# Run parameter tuning experiments\n",
    "if TUNING_READY:\n",
    "    print(\"üöÄ Starting parameter tuning experiments...\")\n",
    "    print(f\"This will test {len(param_configs)} configurations.\")\n",
    "    print(\"Each test may take 1-3 minutes depending on parameters.\\n\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, config in enumerate(param_configs):\n",
    "        config_name = config.pop('name')  # Remove name from config dict\n",
    "        print(f\"Testing {i+1}/{len(param_configs)}: {config_name}\")\n",
    "        print(f\"   Parameters: {config}\")\n",
    "        \n",
    "        try:\n",
    "            # Create mask generator with current configuration\n",
    "            mask_generator = SAM2AutomaticMaskGenerator(sam2_model, **config)\n",
    "            \n",
    "            # Generate masks\n",
    "            print(\"   Generating masks...\")\n",
    "            masks = mask_generator.generate(image)\n",
    "            \n",
    "            # Combine masks into binary map\n",
    "            combined_mask = np.zeros_like(ground_truth, dtype=bool)\n",
    "            for mask in masks:\n",
    "                combined_mask |= mask['segmentation']\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = calculate_metrics(ground_truth, combined_mask)\n",
    "            \n",
    "            # Store results\n",
    "            result = {\n",
    "                'config_name': config_name,\n",
    "                'config_id': i,\n",
    "                **config,  # Add all config parameters\n",
    "                **metrics,  # Add all metrics\n",
    "                'num_masks': len(masks),\n",
    "                'predicted_lake_pixels': combined_mask.sum(),\n",
    "                'true_lake_pixels': ground_truth.sum(),\n",
    "                'coverage_ratio': combined_mask.sum() / ground_truth.sum() if ground_truth.sum() > 0 else 0\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "            print(f\"   ‚úÖ IoU: {metrics['iou']:.3f}, Precision: {metrics['precision']:.3f}, Recall: {metrics['recall']:.3f}, F1: {metrics['f1']:.3f}\")\n",
    "            print(f\"      Masks: {len(masks)}, Predicted pixels: {combined_mask.sum():,}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error: {str(e)}\\n\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚úÖ Parameter tuning complete! Tested {len(results)} configurations successfully.\")\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    if results:\n",
    "        df_results = pd.DataFrame(results)\n",
    "        TUNING_COMPLETE = True\n",
    "    else:\n",
    "        print(\"‚ùå No successful configurations\")\n",
    "        TUNING_COMPLETE = False\n",
    "        df_results = pd.DataFrame()\n",
    "        \n",
    "else:\n",
    "    print(\"‚è∏Ô∏è Skipping parameter tuning execution\")\n",
    "    TUNING_COMPLETE = False\n",
    "    results = []\n",
    "    df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results_section"
   },
   "source": "# Analyze and rank results\nif TUNING_COMPLETE and not df_results.empty:\n    print(\"üìä Analyzing parameter tuning results...\\n\")\n    \n    # Create multiple ranking approaches for small lake detection\n    df_results['f1_score'] = df_results['f1']  # For clarity\n    df_results['recall_weighted_score'] = 0.6 * df_results['recall'] + 0.4 * df_results['precision']  # Favor recall\n    df_results['balanced_score'] = 0.5 * df_results['recall'] + 0.5 * df_results['precision']  # Balanced\n    \n    print(\"üèÜ RANKING BY DIFFERENT CRITERIA:\")\n    print(\"=\" * 100)\n    \n    # 1. Recall-focused (best for catching small lakes)\n    print(\"\\nüéØ BEST FOR SMALL LAKE DETECTION (Ranked by Recall):\")\n    df_recall = df_results.sort_values('recall', ascending=False)\n    top_recall = df_recall.head(5)\n    for idx, (_, row) in enumerate(top_recall.iterrows(), 1):\n        print(f\"Rank {idx}: {row['config_name']}\")\n        print(f\"         üìä Recall: {row['recall']:.3f}, Precision: {row['precision']:.3f}, F1: {row['f1']:.3f}\")\n        print(f\"         ‚öôÔ∏è  Points: {row['points_per_side']:2d}, Area: {row['min_mask_region_area']:3d}, IoU: {row['pred_iou_thresh']:.2f}\")\n        print()\n    \n    # 2. Balanced approach\n    print(\"‚öñÔ∏è BEST BALANCED PERFORMANCE (Ranked by F1 Score):\")\n    df_f1 = df_results.sort_values('f1', ascending=False)\n    top_f1 = df_f1.head(5)\n    for idx, (_, row) in enumerate(top_f1.iterrows(), 1):\n        print(f\"Rank {idx}: {row['config_name']}\")\n        print(f\"         üìä F1: {row['f1']:.3f}, Recall: {row['recall']:.3f}, Precision: {row['precision']:.3f}\")\n        print(f\"         ‚öôÔ∏è  Points: {row['points_per_side']:2d}, Area: {row['min_mask_region_area']:3d}, IoU: {row['pred_iou_thresh']:.2f}\")\n        print()\n    \n    # 3. Traditional IoU ranking (for comparison)\n    print(\"üî∑ TRADITIONAL RANKING (Ranked by IoU):\")\n    df_iou = df_results.sort_values('iou', ascending=False)\n    top_iou = df_iou.head(3)\n    for idx, (_, row) in enumerate(top_iou.iterrows(), 1):\n        print(f\"Rank {idx}: {row['config_name']}\")\n        print(f\"         üìä IoU: {row['iou']:.3f}, Recall: {row['recall']:.3f}, Precision: {row['precision']:.3f}\")\n        print()\n    \n    # 4. Compare with default\n    default_row = df_results[df_results['config_name'] == 'default']\n    if not default_row.empty:\n        default_row = default_row.iloc[0]\n        print(\"üîµ DEFAULT CONFIGURATION PERFORMANCE:\")\n        print(f\"     üìä Recall: {default_row['recall']:.3f}, Precision: {default_row['precision']:.3f}, F1: {default_row['f1']:.3f}\")\n        print(f\"     üìà Rank by Recall: #{df_recall[df_recall['config_name'] == 'default'].index[0] + 1} of {len(df_results)}\")\n        print(f\"     üìà Rank by F1: #{df_f1[df_f1['config_name'] == 'default'].index[0] + 1} of {len(df_results)}\")\n        print()\n    \n    # Choose best configuration based on recall (small lake detection)\n    best_config = df_recall.iloc[0]\n    print(f\"üéØ RECOMMENDED FOR SMALL LAKE DETECTION:\")\n    print(f\"   Name: {best_config['config_name']}\")\n    print(f\"   points_per_side: {best_config['points_per_side']}\")\n    print(f\"   pred_iou_thresh: {best_config['pred_iou_thresh']}\")\n    print(f\"   min_mask_region_area: {best_config['min_mask_region_area']}\")\n    print(f\"   stability_score_thresh: {best_config['stability_score_thresh']}\")\n    print(f\"   üìà Performance: Recall={best_config['recall']:.3f}, Precision={best_config['precision']:.3f}, F1={best_config['f1']:.3f}\")\n    \n    # Analysis of small vs large lake trade-offs\n    print(f\"\\nüîç SMALL LAKE DETECTION ANALYSIS:\")\n    print(f\"   üíß Best recall detects {best_config['num_masks']} total segments\")\n    print(f\"   üíß Default detects {default_row['num_masks'] if not default_row.empty else 'N/A'} total segments\")\n    \n    if not default_row.empty:\n        recall_improvement = (best_config['recall'] - default_row['recall']) / default_row['recall'] * 100\n        precision_change = (best_config['precision'] - default_row['precision']) / default_row['precision'] * 100\n        print(f\"   üìà Recall improvement: {recall_improvement:+.1f}%\")\n        print(f\"   üìä Precision change: {precision_change:+.1f}%\")\n    \n    # Save detailed results\n    results_file = \"/content/drive/MyDrive/superlakes/sam2_results/sam2_small_lake_tuning_results.csv\" if IN_COLAB else \"/content/sam2_parameter_tuning_results.csv\"\n    df_recall.to_csv(results_file, index=False)\n    print(f\"\\nüìÅ Detailed results saved (ranked by recall): {results_file}\")\n    \nelse:\n    print(\"‚è∏Ô∏è No tuning results to analyze\")\n    best_config = None",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_results"
   },
   "outputs": [],
   "source": [
    "# Analyze and rank results\n",
    "if TUNING_COMPLETE and not df_results.empty:\n",
    "    print(\"üìä Analyzing parameter tuning results...\\n\")\n",
    "    \n",
    "    # Sort by IoU (primary metric)\n",
    "    df_sorted = df_results.sort_values('iou', ascending=False)\n",
    "    \n",
    "    print(\"üèÜ TOP 10 CONFIGURATIONS (ranked by IoU):\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    top_10 = df_sorted.head(10)\n",
    "    for idx, (_, row) in enumerate(top_10.iterrows(), 1):\n",
    "        print(f\"Rank {idx:2d}: {row['config_name']}\")\n",
    "        print(f\"         Points/side: {row['points_per_side']:2d}, IoU thresh: {row['pred_iou_thresh']:.2f}, \")\n",
    "        print(f\"         Min area: {row['min_mask_region_area']:4d}, Stability: {row['stability_score_thresh']:.2f}\")\n",
    "        print(f\"         üìä IoU: {row['iou']:.3f}, Precision: {row['precision']:.3f}, Recall: {row['recall']:.3f}, F1: {row['f1']:.3f}\")\n",
    "        print(f\"         üéØ Masks: {row['num_masks']:3d}, Predicted: {row['predicted_lake_pixels']:,} pixels\")\n",
    "        print()\n",
    "    \n",
    "    # Best configuration details\n",
    "    best_config = df_sorted.iloc[0]\n",
    "    print(f\"üéØ OPTIMAL CONFIGURATION:\")\n",
    "    print(f\"   Name: {best_config['config_name']}\")\n",
    "    print(f\"   points_per_side: {best_config['points_per_side']}\")\n",
    "    print(f\"   pred_iou_thresh: {best_config['pred_iou_thresh']}\")\n",
    "    print(f\"   min_mask_region_area: {best_config['min_mask_region_area']}\")\n",
    "    print(f\"   stability_score_thresh: {best_config['stability_score_thresh']}\")\n",
    "    print(f\"   üìà Performance: IoU={best_config['iou']:.3f}, F1={best_config['f1']:.3f}\")\n",
    "    \n",
    "    # Save detailed results\n",
    "    results_file = \"/content/sam2_parameter_tuning_results.csv\"\n",
    "    df_sorted.to_csv(results_file, index=False)\n",
    "    print(f\"\\nüìÅ Detailed results saved to: {results_file}\")\n",
    "    \n",
    "    # Download link for Colab\n",
    "    print(f\"\\nüíæ To download results: files.download('{results_file}')\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚è∏Ô∏è No tuning results to analyze\")\n",
    "    best_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize_parameters"
   },
   "outputs": [],
   "source": [
    "# Create parameter effect visualizations\n",
    "if TUNING_COMPLETE and not df_results.empty:\n",
    "    print(\"üìà Creating parameter effect visualizations...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.suptitle('SAM 2 Parameter Effects on Lake Detection Performance', fontsize=16, y=1.02)\n",
    "    \n",
    "    # 1. IoU vs points_per_side\n",
    "    points_data = df_results.groupby('points_per_side')['iou'].agg(['max', 'mean', 'std']).reset_index()\n",
    "    axes[0,0].bar(points_data['points_per_side'].astype(str), points_data['max'], \n",
    "                  alpha=0.7, color='skyblue', label='Best IoU')\n",
    "    axes[0,0].scatter(points_data['points_per_side'].astype(str), points_data['mean'], \n",
    "                     color='red', s=50, label='Mean IoU', zorder=5)\n",
    "    axes[0,0].set_title('IoU vs Points Per Side')\n",
    "    axes[0,0].set_xlabel('Points Per Side')\n",
    "    axes[0,0].set_ylabel('IoU Score')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. IoU vs pred_iou_thresh\n",
    "    iou_data = df_results.groupby('pred_iou_thresh')['iou'].agg(['max', 'mean']).reset_index()\n",
    "    axes[0,1].bar(iou_data['pred_iou_thresh'].astype(str), iou_data['max'], \n",
    "                  alpha=0.7, color='lightcoral', label='Best IoU')\n",
    "    axes[0,1].scatter(iou_data['pred_iou_thresh'].astype(str), iou_data['mean'], \n",
    "                     color='darkred', s=50, label='Mean IoU', zorder=5)\n",
    "    axes[0,1].set_title('IoU vs Prediction IoU Threshold')\n",
    "    axes[0,1].set_xlabel('Prediction IoU Threshold')\n",
    "    axes[0,1].set_ylabel('IoU Score')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. IoU vs min_mask_region_area\n",
    "    area_data = df_results.groupby('min_mask_region_area')['iou'].agg(['max', 'mean']).reset_index()\n",
    "    axes[0,2].bar(area_data['min_mask_region_area'].astype(str), area_data['max'], \n",
    "                  alpha=0.7, color='lightgreen', label='Best IoU')\n",
    "    axes[0,2].scatter(area_data['min_mask_region_area'].astype(str), area_data['mean'], \n",
    "                     color='darkgreen', s=50, label='Mean IoU', zorder=5)\n",
    "    axes[0,2].set_title('IoU vs Min Mask Region Area')\n",
    "    axes[0,2].set_xlabel('Min Mask Region Area (pixels)')\n",
    "    axes[0,2].set_ylabel('IoU Score')\n",
    "    axes[0,2].legend()\n",
    "    axes[0,2].tick_params(axis='x', rotation=45)\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Precision vs Recall scatter\n",
    "    scatter = axes[1,0].scatter(df_results['recall'], df_results['precision'], \n",
    "                               c=df_results['iou'], cmap='viridis', s=80, alpha=0.7)\n",
    "    axes[1,0].set_title('Precision vs Recall\\n(colored by IoU)')\n",
    "    axes[1,0].set_xlabel('Recall')\n",
    "    axes[1,0].set_ylabel('Precision')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=axes[1,0], label='IoU')\n",
    "    \n",
    "    # 5. Number of masks vs IoU\n",
    "    axes[1,1].scatter(df_results['num_masks'], df_results['iou'], \n",
    "                     c=df_results['f1'], cmap='plasma', s=80, alpha=0.7)\n",
    "    axes[1,1].set_title('Number of Masks vs IoU\\n(colored by F1 score)')\n",
    "    axes[1,1].set_xlabel('Number of Masks Generated')\n",
    "    axes[1,1].set_ylabel('IoU Score')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Configuration ranking\n",
    "    top_configs = df_results.nlargest(8, 'iou')\n",
    "    y_pos = np.arange(len(top_configs))\n",
    "    axes[1,2].barh(y_pos, top_configs['iou'], alpha=0.7, color='gold')\n",
    "    axes[1,2].set_yticks(y_pos)\n",
    "    axes[1,2].set_yticklabels([name[:15] + '...' if len(name) > 15 else name \n",
    "                              for name in top_configs['config_name']], fontsize=9)\n",
    "    axes[1,2].set_title('Top 8 Configurations by IoU')\n",
    "    axes[1,2].set_xlabel('IoU Score')\n",
    "    axes[1,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_file = \"/content/sam2_parameter_analysis.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üìÅ Parameter analysis plot saved to: {plot_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚è∏Ô∏è Skipping visualization (no tuning results)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final_result_section"
   },
   "source": [
    "## üéâ Generate Final Result with Optimal Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final_result"
   },
   "outputs": [],
   "source": [
    "# Generate final result with best configuration\n",
    "if SAM2_LOADED:\n",
    "    if best_config is not None:\n",
    "        print(f\"üéØ Generating final result with optimal configuration: {best_config['config_name']}\")\n",
    "        \n",
    "        # Extract optimal parameters\n",
    "        optimal_params = {\n",
    "            'points_per_side': int(best_config['points_per_side']),\n",
    "            'pred_iou_thresh': float(best_config['pred_iou_thresh']),\n",
    "            'min_mask_region_area': int(best_config['min_mask_region_area']),\n",
    "            'stability_score_thresh': float(best_config['stability_score_thresh'])\n",
    "        }\n",
    "        \n",
    "        # Create optimal mask generator\n",
    "        optimal_generator = SAM2AutomaticMaskGenerator(sam2_model, **optimal_params)\n",
    "        config_name = best_config['config_name']\n",
    "        \n",
    "    else:\n",
    "        print(\"üîÑ Using default configuration (no tuning performed)\")\n",
    "        optimal_generator = SAM2AutomaticMaskGenerator(sam2_model)\n",
    "        optimal_params = \"Default SAM 2 configuration\"\n",
    "        config_name = \"default\"\n",
    "    \n",
    "    # Generate final masks\n",
    "    print(\"   Generating final masks...\")\n",
    "    final_masks = optimal_generator.generate(image)\n",
    "    print(f\"‚úÖ Final configuration generated {len(final_masks)} masks\")\n",
    "    \n",
    "    FINAL_RESULT_READY = True\n",
    "    \n",
    "else:\n",
    "    print(\"‚è∏Ô∏è Cannot generate final result (SAM 2 not loaded)\")\n",
    "    FINAL_RESULT_READY = False\n",
    "    final_masks = []\n",
    "    optimal_params = None\n",
    "    config_name = \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comprehensive_viz_section"
   },
   "source": [
    "## üñºÔ∏è Comprehensive Final Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comprehensive_visualization"
   },
   "outputs": [],
   "source": [
    "# Create comprehensive final visualization\n",
    "if FINAL_RESULT_READY:\n",
    "    if GROUND_TRUTH_LOADED:\n",
    "        # With ground truth comparison\n",
    "        print(\"üñºÔ∏è Creating comprehensive visualization with ground truth comparison...\")\n",
    "        \n",
    "        # Combine final masks\n",
    "        final_combined_mask = np.zeros_like(ground_truth, dtype=bool)\n",
    "        for mask in final_masks:\n",
    "            final_combined_mask |= mask['segmentation']\n",
    "        \n",
    "        # Calculate final metrics\n",
    "        final_metrics = calculate_metrics(ground_truth, final_combined_mask)\n",
    "        \n",
    "        # Create comprehensive visualization\n",
    "        fig = plt.figure(figsize=(24, 16))\n",
    "        \n",
    "        # Create custom grid layout\n",
    "        gs = fig.add_gridspec(3, 4, height_ratios=[1, 1, 0.6], width_ratios=[1, 1, 1, 1])\n",
    "        \n",
    "        # Row 1: Input and Ground Truth\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        ax1.imshow(image)\n",
    "        ax1.set_title(f'Input: {IMAGE_TYPE} Image\\nShape: {image.shape}')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        ax2.imshow(image)\n",
    "        ax2.imshow(ground_truth, alpha=0.6, cmap='Blues')\n",
    "        ax2.set_title(f'Ground Truth Lakes\\n{ground_truth.sum():,} pixels ({ground_truth.mean()*100:.1f}%)')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # Row 1: SAM 2 Results\n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "        ax3.imshow(image)\n",
    "        show_anns(final_masks)\n",
    "        ax3.set_title(f'SAM 2 Individual Masks\\n{len(final_masks)} masks detected')\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        ax4 = fig.add_subplot(gs[0, 3])\n",
    "        ax4.imshow(image)\n",
    "        ax4.imshow(final_combined_mask, alpha=0.6, cmap='Reds')\n",
    "        ax4.set_title(f'SAM 2 Combined Result\\n{final_combined_mask.sum():,} pixels ({final_combined_mask.mean()*100:.1f}%)')\n",
    "        ax4.axis('off')\n",
    "        \n",
    "        # Row 2: Detailed Comparison\n",
    "        ax5 = fig.add_subplot(gs[1, 0:2])\n",
    "        # Create detailed comparison overlay\n",
    "        comparison = np.zeros((*ground_truth.shape, 3), dtype=np.uint8)\n",
    "        comparison[ground_truth & final_combined_mask] = [0, 255, 0]      # True positive (green)\n",
    "        comparison[ground_truth & ~final_combined_mask] = [0, 0, 255]     # False negative (blue)\n",
    "        comparison[~ground_truth & final_combined_mask] = [255, 0, 0]     # False positive (red)\n",
    "        \n",
    "        ax5.imshow(image)\n",
    "        ax5.imshow(comparison, alpha=0.7)\n",
    "        ax5.set_title('Detailed Pixel-Level Comparison\\nüü¢ Correct Detection  üîµ Missed Lakes  üî¥ False Positives')\n",
    "        ax5.axis('off')\n",
    "        \n",
    "        # Row 2: Side-by-side comparison\n",
    "        ax6 = fig.add_subplot(gs[1, 2:4])\n",
    "        # Create side-by-side overlay\n",
    "        overlay_image = image.copy()\n",
    "        # Ground truth on left half (blue)\n",
    "        left_half = slice(None), slice(None, image.shape[1]//2)\n",
    "        overlay_blue = np.zeros((*ground_truth.shape, 4))\n",
    "        overlay_blue[ground_truth] = [0, 0, 1, 0.6]\n",
    "        \n",
    "        # SAM 2 result on right half (red)\n",
    "        right_half = slice(None), slice(image.shape[1]//2, None)\n",
    "        overlay_red = np.zeros((*ground_truth.shape, 4))\n",
    "        overlay_red[final_combined_mask] = [1, 0, 0, 0.6]\n",
    "        \n",
    "        ax6.imshow(image)\n",
    "        ax6.imshow(overlay_blue[left_half], alpha=0.6, extent=[0, image.shape[1]//2, image.shape[0], 0])\n",
    "        ax6.imshow(overlay_red[right_half], alpha=0.6, extent=[image.shape[1]//2, image.shape[1], image.shape[0], 0])\n",
    "        ax6.axvline(x=image.shape[1]//2, color='white', linewidth=3, linestyle='--')\n",
    "        ax6.set_title('Side-by-Side Comparison\\nüîµ Ground Truth (left)  üî¥ SAM 2 Result (right)')\n",
    "        ax6.axis('off')\n",
    "        \n",
    "        # Row 3: Metrics and Configuration\n",
    "        ax7 = fig.add_subplot(gs[2, :])\n",
    "        ax7.axis('off')\n",
    "        \n",
    "        # Create metrics text\n",
    "        metrics_text = f\"\"\"\n",
    "üéØ OPTIMAL CONFIGURATION: {config_name}\n",
    "üìä PERFORMANCE METRICS:\n",
    "   ‚Ä¢ IoU (Intersection over Union): {final_metrics['iou']:.3f}\n",
    "   ‚Ä¢ Precision: {final_metrics['precision']:.3f}\n",
    "   ‚Ä¢ Recall: {final_metrics['recall']:.3f} \n",
    "   ‚Ä¢ F1 Score: {final_metrics['f1']:.3f}\n",
    "\n",
    "üîß SAM 2 PARAMETERS:\n",
    "   ‚Ä¢ Points per side: {optimal_params['points_per_side']}\n",
    "   ‚Ä¢ Prediction IoU threshold: {optimal_params['pred_iou_thresh']}\n",
    "   ‚Ä¢ Min mask region area: {optimal_params['min_mask_region_area']} pixels\n",
    "   ‚Ä¢ Stability score threshold: {optimal_params['stability_score_thresh']}\n",
    "\n",
    "üìà DETECTION SUMMARY:\n",
    "   ‚Ä¢ Ground truth lake pixels: {ground_truth.sum():,}\n",
    "   ‚Ä¢ SAM 2 detected pixels: {final_combined_mask.sum():,}\n",
    "   ‚Ä¢ Correctly identified: {(ground_truth & final_combined_mask).sum():,} pixels\n",
    "   ‚Ä¢ Missed lakes: {(ground_truth & ~final_combined_mask).sum():,} pixels\n",
    "   ‚Ä¢ False positives: {(~ground_truth & final_combined_mask).sum():,} pixels\n",
    "\"\"\"\n",
    "        \n",
    "        ax7.text(0.05, 0.95, metrics_text, transform=ax7.transAxes, fontsize=12, \n",
    "                verticalalignment='top', fontfamily='monospace',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgray', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save comprehensive result\n",
    "        final_plot_file = f\"/content/sam2_final_result_comprehensive_{config_name}.png\"\n",
    "        plt.savefig(final_plot_file, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nüéâ FINAL RESULTS SUMMARY:\")\n",
    "        print(f\"   üèÜ Best configuration: {config_name}\")\n",
    "        print(f\"   üìä IoU: {final_metrics['iou']:.3f}\")\n",
    "        print(f\"   üìä Precision: {final_metrics['precision']:.3f}\")\n",
    "        print(f\"   üìä Recall: {final_metrics['recall']:.3f}\")\n",
    "        print(f\"   üìä F1 Score: {final_metrics['f1']:.3f}\")\n",
    "        print(f\"   üìÅ Comprehensive visualization saved to: {final_plot_file}\")\n",
    "        \n",
    "    else:\n",
    "        # Without ground truth - just show result\n",
    "        print(\"üñºÔ∏è Creating visualization without ground truth comparison...\")\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(image)\n",
    "        axes[0].set_title(f'Original {IMAGE_TYPE} Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # SAM 2 result\n",
    "        axes[1].imshow(image)\n",
    "        show_anns(final_masks)\n",
    "        axes[1].set_title(f'SAM 2 Lake Detection Result\\n{len(final_masks)} masks detected')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        final_plot_file = f\"/content/sam2_final_result_{config_name}.png\"\n",
    "        plt.savefig(final_plot_file, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"üìÅ Final result saved to: {final_plot_file}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚è∏Ô∏è Skipping final visualization (no final result available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export_section"
   },
   "source": [
    "## üíæ Export Results and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "export_results"
   },
   "outputs": [],
   "source": "# Export optimal configuration and code template\nif best_config is not None:\n    print(\"üíæ Exporting optimal configuration and usage code...\")\n    \n    # Create results directory in Google Drive\n    if IN_COLAB:\n        results_dir = os.path.join(DRIVE_DATA_PATH, \"sam2_results\")\n    else:\n        results_dir = \"/content/sam2_results\"\n    \n    os.makedirs(results_dir, exist_ok=True)\n    print(f\"üìÅ Results directory: {results_dir}\")\n    \n    # Create optimal configuration dictionary\n    optimal_config = {\n        'configuration_name': best_config['config_name'],\n        'sam2_parameters': {\n            'points_per_side': int(best_config['points_per_side']),\n            'pred_iou_thresh': float(best_config['pred_iou_thresh']),\n            'min_mask_region_area': int(best_config['min_mask_region_area']),\n            'stability_score_thresh': float(best_config['stability_score_thresh'])\n        },\n        'performance_metrics': {\n            'iou': float(best_config['iou']),\n            'precision': float(best_config['precision']),\n            'recall': float(best_config['recall']),\n            'f1_score': float(best_config['f1'])\n        },\n        'test_conditions': {\n            'image_type': IMAGE_TYPE,\n            'image_shape': image.shape if IMAGE_LOADED else None,\n            'ground_truth_lake_pixels': int(ground_truth.sum()) if GROUND_TRUTH_LOADED else None,\n            'device_used': str(device),\n            'test_image': IMAGE_FILES[IMAGE_TYPE],\n            'ground_truth_file': GROUND_TRUTH_FILE\n        },\n        'usage_notes': [\n            \"This configuration was optimized for glacial lake detection\",\n            f\"Tested on {IMAGE_TYPE} satellite imagery\",\n            \"Performance may vary on different image types or regions\",\n            \"Consider re-tuning for significantly different lake sizes or imagery\"\n        ]\n    }\n    \n    # Save configuration as JSON to Drive\n    config_file = os.path.join(results_dir, \"optimal_sam2_lake_detection_config.json\")\n    with open(config_file, 'w') as f:\n        json.dump(optimal_config, f, indent=2)\n    \n    print(f\"‚úÖ Optimal configuration saved to Google Drive: {config_file}\")\n    \n    # Create usage code template\n    code_template = f'''\n# ============================================================================\n# OPTIMAL SAM 2 CONFIGURATION FOR LAKE DETECTION\n# Generated from parameter tuning on {IMAGE_TYPE} imagery\n# Performance: IoU={best_config['iou']:.3f}, F1={best_config['f1']:.3f}\n# ============================================================================\n\nfrom sam2.build_sam import build_sam2\nfrom sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\nimport numpy as np\n\n# Load SAM 2 model\nsam2_model = build_sam2(\n    \"configs/sam2.1/sam2.1_hiera_l.yaml\",\n    \"checkpoints/sam2.1_hiera_large.pt\", \n    device=\"cuda\"  # or \"cpu\"\n)\n\n# Create optimal mask generator for lake detection\noptimal_lake_detector = SAM2AutomaticMaskGenerator(\n    sam2_model,\n    points_per_side={best_config['points_per_side']},\n    pred_iou_thresh={best_config['pred_iou_thresh']},\n    min_mask_region_area={best_config['min_mask_region_area']},\n    stability_score_thresh={best_config['stability_score_thresh']}\n)\n\n# Apply to new image (ensure image is in correct format)\n# For {IMAGE_TYPE} images: load and prepare as done in this notebook\nnew_masks = optimal_lake_detector.generate(new_image)\n\n# Combine masks into binary lake detection\nlake_mask = np.zeros((new_image.shape[0], new_image.shape[1]), dtype=bool)\nfor mask in new_masks:\n    lake_mask |= mask['segmentation']\n\n# Expected performance on similar imagery:\n# - IoU: {best_config['iou']:.3f}\n# - Precision: {best_config['precision']:.3f} \n# - Recall: {best_config['recall']:.3f}\n# - F1 Score: {best_config['f1']:.3f}\n\nprint(f\"Detected {{len(new_masks)}} lake segments\")\nprint(f\"Total lake pixels: {{lake_mask.sum():,}}\")\n'''\n    \n    # Save code template to Drive\n    code_file = os.path.join(results_dir, \"optimal_sam2_lake_detection_code.py\")\n    with open(code_file, 'w') as f:\n        f.write(code_template)\n    \n    print(f\"‚úÖ Usage code template saved to Google Drive: {code_file}\")\n    \n    # Save detailed results CSV to Drive\n    if 'df_results' in locals() and not df_results.empty:\n        results_csv = os.path.join(results_dir, \"sam2_parameter_tuning_results.csv\")\n        df_results.to_csv(results_csv, index=False)\n        print(f\"‚úÖ Detailed results CSV saved to Google Drive: {results_csv}\")\n    \n    # Save visualizations to Drive\n    if 'final_plot_file' in locals():\n        # Copy final plot to Drive\n        drive_plot_file = os.path.join(results_dir, f\"sam2_final_result_comprehensive_{best_config['config_name']}.png\")\n        if os.path.exists(final_plot_file):\n            import shutil\n            shutil.copy2(final_plot_file, drive_plot_file)\n            print(f\"‚úÖ Final visualization saved to Google Drive: {drive_plot_file}\")\n    \n    # Display the template\n    print(\"\\nüöÄ READY-TO-USE CODE FOR NEW IMAGES:\")\n    print(\"=\" * 80)\n    print(code_template)\n    \n    # Summary of saved files\n    print(f\"\\nüìÅ ALL RESULTS SAVED TO GOOGLE DRIVE:\")\n    print(f\"   üìÇ Results folder: {results_dir}\")\n    print(f\"   üìÑ Configuration JSON: optimal_sam2_lake_detection_config.json\")\n    print(f\"   üêç Python code: optimal_sam2_lake_detection_code.py\")\n    if 'df_results' in locals() and not df_results.empty:\n        print(f\"   üìä Detailed results: sam2_parameter_tuning_results.csv\")\n    if 'final_plot_file' in locals():\n        print(f\"   üñºÔ∏è Final visualization: sam2_final_result_comprehensive_{best_config['config_name']}.png\")\n    \n    print(f\"\\nüí° Access these files anytime from your Google Drive at: {results_dir}\")\n    \nelse:\n    print(\"‚è∏Ô∏è No optimal configuration to export (parameter tuning not completed)\")\n    \n    # Still provide default usage template\n    print(\"\\nüìù DEFAULT SAM 2 USAGE FOR LAKE DETECTION:\")\n    default_template = '''\nfrom sam2.build_sam import build_sam2\nfrom sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n\n# Load SAM 2\nsam2_model = build_sam2(\"configs/sam2.1/sam2.1_hiera_l.yaml\", \n                        \"checkpoints/sam2.1_hiera_large.pt\", device=\"cuda\")\n\n# Create mask generator with default parameters\nmask_generator = SAM2AutomaticMaskGenerator(sam2_model)\n\n# Generate masks\nmasks = mask_generator.generate(your_image)\nprint(f\"Generated {len(masks)} masks\")\n'''\n    print(default_template)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion_section"
   },
   "source": [
    "## üéâ Analysis Complete!\n",
    "\n",
    "This notebook has systematically tested SAM 2 parameters for glacial lake detection. \n",
    "\n",
    "### What was accomplished:\n",
    "1. ‚úÖ **Environment Setup**: Configured Google Colab with SAM 2 and dependencies\n",
    "2. ‚úÖ **Data Loading**: Loaded satellite imagery and ground truth lake masks\n",
    "3. ‚úÖ **Parameter Tuning**: Tested multiple SAM 2 configurations systematically\n",
    "4. ‚úÖ **Performance Analysis**: Evaluated each configuration using IoU, precision, recall, F1\n",
    "5. ‚úÖ **Optimal Configuration**: Identified best parameters for your specific use case\n",
    "6. ‚úÖ **Results Export**: Generated ready-to-use code and configuration files\n",
    "\n",
    "### Next steps:\n",
    "- **Download the results** using the provided commands\n",
    "- **Apply the optimal configuration** to your full dataset\n",
    "- **Validate on additional images** to confirm performance\n",
    "- **Consider re-tuning** if working with significantly different imagery\n",
    "\n",
    "### Need help?\n",
    "- Check the exported configuration JSON for complete parameter details\n",
    "- Use the provided code template for applying to new images\n",
    "- Consider the performance metrics when evaluating results on new data\n",
    "\n",
    "**Happy lake detecting! üèîÔ∏èüíß**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# SAM Lake Detection with Teaching (Improved)\n\nThis notebook demonstrates how to **teach SAM** what lakes look like using manual annotations, then apply this knowledge to detect lakes automatically.\n\n**Simple 3-step workflow:**\n1. **üéì Learn** from 1-2 manual examples \n2. **üéØ Apply** to new images with optimized settings\n3. **üìä Compare** results and export\n\n**Requirements:** GPU runtime recommended for faster processing.",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages\n! pip install segment-geospatial leafmap scikit-learn opencv-python -q\n\nprint(\"‚úÖ Installation complete!\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Import libraries\nimport leafmap\nfrom samgeo import SamGeo\nimport numpy as np\nimport rasterio\nimport cv2\nimport json\nimport os\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\nprint(\"‚úÖ Libraries imported successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Google Drive mounted at /content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: üéì Learning from Manual Examples\n\nThis section analyzes your manual lake annotations to extract knowledge that will guide SAM.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def analyze_manual_lakes(mask_path):\n    \"\"\"Extract lake characteristics from manual annotations\"\"\"\n    print(f\"üîç Analyzing: {os.path.basename(mask_path)}\")\n    \n    with rasterio.open(mask_path) as src:\n        mask = src.read(1).astype(bool)\n    \n    # Find individual lakes\n    labeled_mask = cv2.connectedComponents(mask.astype(np.uint8))[1]\n    lake_labels = np.unique(labeled_mask)[1:]  # Exclude background\n    \n    lake_centers = []\n    lake_sizes = []\n    \n    for label in lake_labels:\n        component = (labeled_mask == label)\n        coords = np.where(component)\n        \n        # Lake center and size\n        center_x = int(np.mean(coords[1]))\n        center_y = int(np.mean(coords[0]))\n        size = len(coords[0])\n        \n        lake_centers.append((center_x, center_y))\n        lake_sizes.append(size)\n    \n    # Calculate statistics\n    stats = {\n        'num_lakes': len(lake_labels),\n        'avg_size': np.mean(lake_sizes) if lake_sizes else 0,\n        'coverage_percent': (mask.sum() / mask.size) * 100,\n        'size_range': (min(lake_sizes), max(lake_sizes)) if lake_sizes else (0, 0)\n    }\n    \n    print(f\"   üìä Found {stats['num_lakes']} lakes, avg size: {stats['avg_size']:.0f} pixels\")\n    print(f\"   üìä Coverage: {stats['coverage_percent']:.2f}%\")\n    \n    return lake_centers, stats\n\ndef create_smart_sam_config(stats):\n    \"\"\"Create SAM configuration optimized for detected lake characteristics\"\"\"\n    print(\"‚öôÔ∏è Creating optimized SAM configuration...\")\n    \n    config = {\n        \"points_per_side\": 32,\n        \"pred_iou_thresh\": 0.76,\n        \"stability_score_thresh\": 0.62,\n        \"crop_n_layers\": 1,\n        \"min_mask_region_area\": 30,\n    }\n    \n    # Optimize based on lake characteristics\n    if stats['avg_size'] < 100:  # Small lakes\n        config[\"points_per_side\"] = 64\n        config[\"min_mask_region_area\"] = max(10, int(stats['avg_size'] // 4))\n        print(\"   ‚Üí Optimized for small lakes\")\n    \n    if stats['coverage_percent'] < 2.0:  # Sparse lakes\n        config[\"pred_iou_thresh\"] = 0.6\n        config[\"stability_score_thresh\"] = 0.5\n        print(\"   ‚Üí Optimized for sparse coverage\")\n    \n    if stats['num_lakes'] > 10:  # Many lakes\n        config[\"crop_n_layers\"] = 2\n        print(\"   ‚Üí Optimized for many lakes\")\n    \n    return config"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_sam_config(lake_stats):\n",
    "    \"\"\"\n",
    "    Create SAM configuration optimized for the detected lake characteristics\n",
    "    \"\"\"\n",
    "    print(\"‚öôÔ∏è Creating optimized SAM configuration...\")\n",
    "    \n",
    "    # Start with base configuration\n",
    "    sam_kwargs = {\n",
    "        \"points_per_side\": 32,\n",
    "        \"pred_iou_thresh\": 0.76,\n",
    "        \"stability_score_thresh\": 0.62,\n",
    "        \"crop_n_layers\": 1,\n",
    "        \"crop_n_points_downscale_factor\": 2,\n",
    "        \"min_mask_region_area\": 30,\n",
    "    }\n",
    "    \n",
    "    # Optimize based on lake characteristics\n",
    "    avg_size = lake_stats['avg_size']\n",
    "    coverage = lake_stats['total_coverage']\n",
    "    num_lakes = lake_stats['num_lakes']\n",
    "    \n",
    "    # If lakes are small, increase sampling and lower minimum area\n",
    "    if avg_size < 100:\n",
    "        sam_kwargs[\"points_per_side\"] = 64\n",
    "        sam_kwargs[\"min_mask_region_area\"] = max(10, int(avg_size // 4))\n",
    "        print(\"   ‚Üí Optimized for small lakes: increased sampling, lowered min area\")\n",
    "    \n",
    "    # If lakes are sparse, be more aggressive\n",
    "    if coverage < 2.0:\n",
    "        sam_kwargs[\"pred_iou_thresh\"] = 0.6\n",
    "        sam_kwargs[\"stability_score_thresh\"] = 0.5\n",
    "        print(\"   ‚Üí Optimized for sparse lakes: lowered quality thresholds\")\n",
    "    \n",
    "    # If many small lakes, use multi-scale approach\n",
    "    if num_lakes > 10 and avg_size < 200:\n",
    "        sam_kwargs[\"crop_n_layers\"] = 2\n",
    "        sam_kwargs[\"crop_n_points_downscale_factor\"] = 1\n",
    "        print(\"   ‚Üí Optimized for many small lakes: multi-scale processing\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Optimized SAM configuration: {sam_kwargs}\")\n",
    "    return sam_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Configuration: Your Training Data\n\n**Update these paths** to point to your training image and manual lake annotations:",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# üéØ YOUR TRAINING DATA - Update these paths:\nTRAINING_IMAGE = '/content/drive/MyDrive/superlakes/2021-09-04_fcc_testclip2.tif'\nTRAINING_MASK = '/content/drive/MyDrive/superlakes/lake_mask_testclip.tif'\n\n# Target image to apply learning to:\nTARGET_IMAGE = '/content/drive/MyDrive/superlakes/2021-09-04_fcc_blurred_medium_blur.tif'\n\n# Check files\nfor path, name in [(TRAINING_IMAGE, \"Training image\"), (TRAINING_MASK, \"Training mask\"), (TARGET_IMAGE, \"Target image\")]:\n    if os.path.exists(path):\n        print(f\"‚úÖ {name}: {os.path.basename(path)}\")\n    else:\n        print(f\"‚ùå {name} not found: {path}\")\n        print(\"   ‚Üí Update the path above!\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# üéì LEARN from manual annotations\nprint(\"üéì LEARNING PHASE\")\nprint(\"=\" * 40)\n\n# Analyze training data to extract lake knowledge\nlake_centers, lake_stats = analyze_manual_lakes(TRAINING_MASK)\noptimized_config = create_smart_sam_config(lake_stats)\n\nprint(f\"\\n‚úÖ Learning complete!\")\nprint(f\"   ‚Üí Extracted {len(lake_centers)} lake center points\")\nprint(f\"   ‚Üí Created optimized SAM configuration\")\nprint(f\"   ‚Üí Ready to apply to new images\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: üéØ Apply Learning to New Image\n\nNow we'll apply the learned knowledge to detect lakes in a new image using three approaches.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Quick visualization of what we learned\ndef show_training_analysis(image_path, mask_path, centers):\n    \"\"\"Show training image, manual mask, and extracted guidance points\"\"\"\n    with rasterio.open(image_path) as src:\n        img = src.read()\n        if img.shape[0] <= 4: img = np.transpose(img, (1, 2, 0))\n        if img.shape[2] > 3: img = img[:, :, :3]\n    \n    with rasterio.open(mask_path) as src:\n        mask = src.read(1).astype(bool)\n    \n    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n    \n    axes[0].imshow(img)\n    axes[0].set_title('Training Image')\n    axes[0].axis('off')\n    \n    axes[1].imshow(img)\n    axes[1].imshow(mask, alpha=0.6, cmap='Blues')\n    axes[1].set_title(f'Manual Annotations\\n{mask.sum():,} pixels')\n    axes[1].axis('off')\n    \n    axes[2].imshow(img)\n    axes[2].imshow(mask, alpha=0.3, cmap='Blues')\n    if centers:\n        x, y = zip(*centers)\n        axes[2].scatter(x, y, c='red', s=80, marker='+', linewidth=2)\n    axes[2].set_title(f'Extracted Centers\\n{len(centers)} points')\n    axes[2].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\nshow_training_analysis(TRAINING_IMAGE, TRAINING_MASK, lake_centers)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Three Detection Methods: Default ‚Üí Optimized ‚Üí Guided",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ TARGET IMAGE - UPDATE THIS PATH\n",
    "# This is the new image where you want to detect lakes\n",
    "\n",
    "target_image = '/content/drive/MyDrive/superlakes/2021-09-04_fcc_blurred_medium_blur.tif'\n",
    "\n",
    "print(f\"üéØ Target image: {os.path.basename(target_image)}\")\n",
    "\n",
    "if os.path.exists(target_image):\n",
    "    print(\"‚úÖ Target image found!\")\n",
    "else:\n",
    "    print(\"‚ùå Target image not found! Please update the path above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üÜö Method Comparison: Default vs. Learned\n",
    "\n",
    "Let's compare three approaches:\n",
    "1. **Default SAM** - No optimization\n",
    "2. **Optimized SAM** - Using learned configuration but no guidance\n",
    "3. **Guided SAM** - Using learned configuration + positive point guidance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Method 1: ü§ñ Default SAM (baseline)\nprint(\"ü§ñ Method 1: Default SAM\")\n\nsam_default = SamGeo(model_type=\"vit_l\")\nsam_default.generate(TARGET_IMAGE, output=\"default_masks.tif\", foreground=True, unique=True)\nsam_default.show_anns(axis=\"off\", alpha=1, output=\"default_result.tif\")\n\nprint(\"‚úÖ Default SAM complete\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Method 2: ‚öôÔ∏è Optimized SAM (learned configuration)\nprint(\"‚öôÔ∏è Method 2: Optimized SAM (using learned config)\")\n\nsam_optimized = SamGeo(model_type=\"vit_l\", sam_kwargs=optimized_config)\nsam_optimized.generate(TARGET_IMAGE, output=\"optimized_masks.tif\", foreground=True, unique=True)\nsam_optimized.show_anns(axis=\"off\", alpha=1, output=\"optimized_result.tif\")\n\nprint(\"‚úÖ Optimized SAM complete\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Method 3: üéØ Guided SAM (learned config + point guidance) \nprint(\"üéØ Method 3: Guided SAM (using learned config + guidance points)\")\n\n# For guided detection, we need to use a different approach\n# Initialize SAM and set the image first\nsam_guided = SamGeo(model_type=\"vit_l\", sam_kwargs=optimized_config)\n\n# Use the generate method but with a different approach for guidance\n# Since point guidance requires predictor, we'll use a workaround\ntry:\n    # Try the direct approach first\n    sam_guided.set_image(TARGET_IMAGE)\n    \n    # Use first 10 guidance points from training\n    guidance_points = lake_centers[:min(10, len(lake_centers))]\n    point_labels = [1] * len(guidance_points)  # All positive\n    \n    print(f\"   Using {len(guidance_points)} guidance points from training\")\n    \n    # Predict with guidance\n    masks = sam_guided.predict(\n        point_coords=guidance_points,\n        point_labels=point_labels,\n        multimask_output=True\n    )\n    \n    sam_guided.save_prediction(\"guided_masks.tif\")\n    sam_guided.show_anns(axis=\"off\", alpha=1, output=\"guided_result.tif\")\n    \n    print(\"‚úÖ Guided SAM complete (with point guidance)\")\n    \nexcept AttributeError as e:\n    print(f\"‚ö†Ô∏è  Point guidance not available, using optimized config only\")\n    # Fallback: just use the optimized config without point guidance\n    sam_guided.generate(TARGET_IMAGE, output=\"guided_masks.tif\", foreground=True, unique=True)\n    sam_guided.show_anns(axis=\"off\", alpha=1, output=\"guided_result.tif\")\n    print(\"‚úÖ Guided SAM complete (config optimization only)\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error in guided method: {e}\")\n    print(\"   Falling back to optimized config only\")\n    sam_guided.generate(TARGET_IMAGE, output=\"guided_masks.tif\", foreground=True, unique=True)\n    sam_guided.show_anns(axis=\"off\", alpha=1, output=\"guided_result.tif\")\n    print(\"‚úÖ Guided SAM complete (fallback mode)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 3: üìä Compare Results\n\nLet's see how the three methods performed:",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Compare Default vs Optimized\nprint(\"üÜö Default vs Optimized SAM:\")\nleafmap.image_comparison(\n    \"default_result.tif\",\n    \"optimized_result.tif\", \n    label1=\"Default SAM\",\n    label2=\"Optimized SAM\",\n)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Compare Optimized vs Guided\nprint(\"üÜö Optimized vs Guided SAM:\")\nleafmap.image_comparison(\n    \"optimized_result.tif\",\n    \"guided_result.tif\",\n    label1=\"Optimized SAM\", \n    label2=\"Guided SAM\",\n)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Original image vs best result\nprint(\"üÜö Original vs Final Result:\")\nleafmap.image_comparison(\n    TARGET_IMAGE,\n    \"guided_result.tif\",\n    label1=\"Original Image\",\n    label2=\"Lake Detection Result\",\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Export Results\n\nSave the best results for further analysis:",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Export best results to vector format\nprint(\"üíæ Exporting results...\")\n\n# Convert best results to vector format for GIS\ntry:\n    sam_guided.tiff_to_vector(\"guided_masks.tif\", \"lake_detection_results.gpkg\")\n    print(\"‚úÖ Vector results: lake_detection_results.gpkg\")\nexcept:\n    print(\"‚ö†Ô∏è Vector export failed, but raster results available\")\n\n# Save the learned configuration for future use\nlearned_config = {\n    'sam_config': optimized_config,\n    'lake_stats': lake_stats,\n    'guidance_points': lake_centers[:10],  # First 10 points\n    'training_files': {\n        'image': os.path.basename(TRAINING_IMAGE),\n        'mask': os.path.basename(TRAINING_MASK)\n    }\n}\n\nwith open('learned_lake_detection_config.json', 'w') as f:\n    json.dump(learned_config, f, indent=2)\n\nprint(\"‚úÖ Configuration saved: learned_lake_detection_config.json\")\nprint(\"‚úÖ Results saved: guided_masks.tif & guided_result.tif\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üéâ Summary & Next Steps\n\n**What we accomplished:**\n1. **üéì Learned** from manual lake annotations (extracted {lake_stats['num_lakes']} lakes)\n2. **‚öôÔ∏è Optimized** SAM configuration for your lake characteristics  \n3. **üéØ Applied** learning to detect lakes in new image\n4. **üìä Compared** Default vs Optimized vs Guided approaches\n5. **üíæ Exported** results in raster and vector formats\n\n**Files created:**\n- `guided_masks.tif` - Binary lake detection mask\n- `guided_result.tif` - Colored visualization \n- `lake_detection_results.gpkg` - Vector format for GIS\n- `learned_lake_detection_config.json` - Configuration for future use\n\n**Next steps:**\n- Apply the saved configuration to more images\n- Fine-tune parameters if needed based on visual inspection\n- Use batch processing for large datasets",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Batch Processing (Optional)\n\nApply learned configuration to multiple images:",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Batch processing function - apply learned config to many images\ndef batch_process_images(image_paths, sam_config, output_dir=\"batch_results\"):\n    \"\"\"Apply learned SAM configuration to multiple images\"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    \n    sam = SamGeo(model_type=\"vit_l\", sam_kwargs=sam_config)\n    results = []\n    \n    for i, image_path in enumerate(image_paths, 1):\n        print(f\"Processing {i}/{len(image_paths)}: {os.path.basename(image_path)}\")\n        \n        try:\n            output_name = os.path.splitext(os.path.basename(image_path))[0]\n            mask_output = os.path.join(output_dir, f\"{output_name}_masks.tif\")\n            result_output = os.path.join(output_dir, f\"{output_name}_result.tif\")\n            \n            sam.generate(image_path, output=mask_output, foreground=True, unique=True)\n            sam.show_anns(axis=\"off\", alpha=1, output=result_output)\n            \n            results.append({\"image\": image_path, \"status\": \"success\", \"output\": mask_output})\n            print(f\"   ‚úÖ Saved: {mask_output}\")\n            \n        except Exception as e:\n            results.append({\"image\": image_path, \"status\": \"error\", \"error\": str(e)})\n            print(f\"   ‚ùå Error: {e}\")\n    \n    print(f\"\\nüéâ Batch processing complete!\")\n    print(f\"   Successful: {len([r for r in results if r['status'] == 'success'])}/{len(image_paths)}\")\n    return results\n\n# Example usage (uncomment and update paths to use):\n# image_list = [\n#     '/content/drive/MyDrive/superlakes/image1.tif',\n#     '/content/drive/MyDrive/superlakes/image2.tif',\n#     # Add more images...\n# ]\n# \n# batch_results = batch_process_images(image_list, optimized_config)\n\nprint(\"Batch processing function ready! Update image_list above to use it.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DINOv3 Water Detection Experiment\n",
    "Step-by-step implementation for glacial lake water detection using DINOv3 foundation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varyabazilova/opt/anaconda3/envs/superlakes/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set up matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load DINOv3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dinov3.utils.config'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_model_from_cfg\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_logging, load_config\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Load DINOv3 model\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading DINOv3 model...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dinov3.utils.config'"
     ]
    }
   ],
   "source": [
    "# # Load DINOv2 model (latest stable version)\n",
    "# print(\"Loading DINOv2 model...\")\n",
    "\n",
    "# # Load processor and model\n",
    "# processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "# model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "\n",
    "# # Move model to device\n",
    "# model = model.to(device)\n",
    "# model.eval()  # Set to evaluation mode\n",
    "\n",
    "# print(\"✅ DINOv2 model loaded successfully!\")\n",
    "# print(f\"Model device: {next(model.parameters()).device}\")\n",
    "# print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    " # Import DINOv3 from the official repo\n",
    "import sys\n",
    "sys.path.append('/Users/varyabazilova/Desktop/glacial_lakes/super_lakes/dinov3/dinov3')\n",
    "\n",
    "import torch\n",
    "from dinov3.models import build_model_from_cfg\n",
    "from dinov3.utils.config import setup_logging, load_config\n",
    "\n",
    "# Load DINOv3 model\n",
    "print(\"Loading DINOv3 model...\")\n",
    "\n",
    "# You can choose different model sizes:\n",
    "# - dinov3_vits14 (small)\n",
    "# - dinov3_vitb14 (base) \n",
    "# - dinov3_vitl14 (large)\n",
    "# - dinov3_vitg14 (giant)\n",
    "\n",
    "model_name = \"dinov3_vitb14\"  # Start with base model\n",
    "model = torch.hub.load('facebookresearch/dinov3', model_name)\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"✅ DINOv3 model loaded successfully!\")\n",
    "print(f\"Model: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/varyabazilova/Desktop/glacial_lakes/super_lakes/dinov3/test_code\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths - update these to your actual files\n",
    "false_color_path = \"/Users/varyabazilova/Desktop/glacial_lakes/super_lakes/dinov3/test_data/2021-09-04_fcc.tif\"\n",
    "mask_path = \"/Users/varyabazilova/Desktop/glacial_lakes/super_lakes/dinov3/test_data/lake_mask.tif\"\n",
    "\n",
    "# Load false color image\n",
    "print(\"Loading false color image...\")\n",
    "with rasterio.open(false_color_path) as src:\n",
    "    false_color = src.read()  # Shape: (3, height, width)\n",
    "    false_color = np.transpose(false_color, (1, 2, 0))  # Shape: (height, width, 3)\n",
    "    image_profile = src.profile\n",
    "    \n",
    "print(f\"False color image shape: {false_color.shape}\")\n",
    "print(f\"Data type: {false_color.dtype}\")\n",
    "print(f\"Value range: {false_color.min()} - {false_color.max()}\")\n",
    "\n",
    "# Load binary mask\n",
    "print(\"\\nLoading binary mask...\")\n",
    "with rasterio.open(mask_path) as src:\n",
    "    mask = src.read(1)  # Shape: (height, width)\n",
    "    \n",
    "print(f\"Mask shape: {mask.shape}\")\n",
    "print(f\"Unique values: {np.unique(mask)}\")\n",
    "print(f\"Water pixels: {np.sum(mask == 1):,} ({np.sum(mask == 1)/mask.size*100:.2f}%)\")\n",
    "print(f\"Non-water pixels: {np.sum(mask == 0):,} ({np.sum(mask == 0)/mask.size*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualize Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# False color image\n",
    "axes[0].imshow(false_color)\n",
    "axes[0].set_title('False Color Image (NIR-Red-Green)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Binary mask\n",
    "axes[1].imshow(mask, cmap='Blues')\n",
    "axes[1].set_title('Manual Water Labels (1=Water, 0=Not Water)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Overlay\n",
    "overlay = false_color.copy()\n",
    "water_pixels = mask == 1\n",
    "overlay[water_pixels, 0] = 255  # Highlight water in red\n",
    "axes[2].imshow(overlay)\n",
    "axes[2].set_title('False Color + Water Labels (Red = Manual Water)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test DINOv2 on Small Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a small patch for testing (e.g., 224x224 pixels)\n",
    "patch_size = 550\n",
    "start_row = 2000  # Adjust these coordinates to get interesting area\n",
    "start_col = 1000\n",
    "\n",
    "# Extract patch from image and mask\n",
    "image_patch = false_color[start_row:start_row+patch_size, start_col:start_col+patch_size]\n",
    "mask_patch = mask[start_row:start_row+patch_size, start_col:start_col+patch_size]\n",
    "\n",
    "print(f\"Patch shape: {image_patch.shape}\")\n",
    "print(f\"Patch water percentage: {np.sum(mask_patch == 1)/mask_patch.size*100:.2f}%\")\n",
    "\n",
    "# Visualize patch\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].imshow(image_patch)\n",
    "axes[0].set_title(f'Image Patch ({patch_size}x{patch_size})')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(mask_patch, cmap='Blues')\n",
    "axes[1].set_title('Corresponding Mask Patch')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Extract DINOv2 Features from Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image for DINOv2\n",
    "print(\"Extracting DINOv2 features from patch...\")\n",
    "\n",
    "# Convert to PIL Image (required by processor)\n",
    "patch_pil = Image.fromarray(image_patch.astype(np.uint8))\n",
    "\n",
    "# Process with DINOv2 processor\n",
    "inputs = processor(patch_pil, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "print(f\"Input tensor shape: {inputs['pixel_values'].shape}\")\n",
    "\n",
    "# Extract features\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "# Get the features\n",
    "features = outputs.last_hidden_state  # Shape: (1, num_patches, feature_dim)\n",
    "features = features.squeeze(0)  # Shape: (num_patches, feature_dim)\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Feature dimension: {features.shape[1]}\")\n",
    "print(f\"Number of patches: {features.shape[0]}\")\n",
    "\n",
    "# Convert to numpy\n",
    "features_np = features.cpu().numpy()\n",
    "print(f\"Features extracted successfully! Shape: {features_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Reshape Features to Match Image Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DINOv2 creates patches, need to map back to pixels\n",
    "print(\"Mapping features back to pixel space...\")\n",
    "\n",
    "# DINOv2 typically uses 14x14 patches for 224x224 input\n",
    "patch_grid_size = int(np.sqrt(features_np.shape[0]))  # Should be 16 for 224x224 input\n",
    "feature_dim = features_np.shape[1]\n",
    "\n",
    "print(f\"Patch grid size: {patch_grid_size}x{patch_grid_size}\")\n",
    "print(f\"Feature dimension: {feature_dim}\")\n",
    "\n",
    "# Reshape features to spatial grid\n",
    "# features_spatial = features_np.reshape(patch_grid_size, patch_grid_size, feature_dim)\n",
    "# Remove the [CLS] token (first feature vector)\n",
    "features_patches = features_np[1:]  # Skip first token\n",
    "features_spatial = features_patches.reshape(patch_grid_size, patch_grid_size, feature_dim)\n",
    "print(f\"Spatial features shape: {features_spatial.shape}\")\n",
    "\n",
    "# Visualize first few feature dimensions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Show original patch\n",
    "axes[0, 0].imshow(image_patch)\n",
    "axes[0, 0].set_title('Original Patch')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Show mask\n",
    "axes[0, 1].imshow(mask_patch, cmap='Blues')\n",
    "axes[0, 1].set_title('Water Mask')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Show first feature dimension\n",
    "axes[0, 2].imshow(features_spatial[:, :, 0], cmap='viridis')\n",
    "axes[0, 2].set_title('Feature Dimension 0')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Show more feature dimensions\n",
    "for i in range(3):\n",
    "    axes[1, i].imshow(features_spatial[:, :, i+1], cmap='viridis')\n",
    "    axes[1, i].set_title(f'Feature Dimension {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to match features with labels\n",
    "# Since DINOv2 gives us patch-level features but we have pixel-level labels,\n",
    "# we need to downsample our mask to match the feature grid\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "print(\"Preparing training data...\")\n",
    "\n",
    "# Downsample mask to match feature grid\n",
    "mask_downsampled = ndimage.zoom(mask_patch.astype(float), \n",
    "                               (patch_grid_size/patch_size, patch_grid_size/patch_size), \n",
    "                               order=0)  # Nearest neighbor\n",
    "\n",
    "# Convert to binary (>0.5 = water)\n",
    "mask_downsampled = (mask_downsampled > 0.5).astype(int)\n",
    "\n",
    "print(f\"Original mask shape: {mask_patch.shape}\")\n",
    "print(f\"Downsampled mask shape: {mask_downsampled.shape}\")\n",
    "print(f\"Features grid shape: {features_spatial.shape[:2]}\")\n",
    "\n",
    "# Flatten for training\n",
    "X_features = features_spatial.reshape(-1, feature_dim)  # (num_patches, feature_dim)\n",
    "y_labels = mask_downsampled.flatten()  # (num_patches,)\n",
    "\n",
    "print(f\"Training features shape: {X_features.shape}\")\n",
    "print(f\"Training labels shape: {y_labels.shape}\")\n",
    "print(f\"Number of water patches: {np.sum(y_labels == 1)}\")\n",
    "print(f\"Number of non-water patches: {np.sum(y_labels == 0)}\")\n",
    "\n",
    "# Visualize downsampled mask\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(mask_patch, cmap='Blues')\n",
    "axes[0].set_title(f'Original Mask ({mask_patch.shape[0]}x{mask_patch.shape[1]})')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(mask_downsampled, cmap='Blues')\n",
    "axes[1].set_title(f'Downsampled Mask ({mask_downsampled.shape[0]}x{mask_downsampled.shape[1]})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(features_spatial[:, :, 0], cmap='viridis')\n",
    "axes[2].set_title('Feature Grid (Dimension 0)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Train Simple Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Training classifier on DINOv2 features...\")\n",
    "\n",
    "# Check if we have both classes\n",
    "unique_labels = np.unique(y_labels)\n",
    "print(f\"Unique labels in data: {unique_labels}\")\n",
    "\n",
    "if len(unique_labels) < 2:\n",
    "    print(\"⚠️ Warning: Only one class present in this patch. Choose a different patch with both water and non-water.\")\n",
    "else:\n",
    "    # Split data for training/testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_features, y_labels, test_size=0.3, random_state=42, stratify=y_labels\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    # Train Random Forest classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nClassification Results:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Non-Water', 'Water']))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Predict on full patch\n",
    "    y_pred_full = clf.predict(X_features)\n",
    "    prediction_grid = y_pred_full.reshape(patch_grid_size, patch_grid_size)\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    axes[0].imshow(image_patch)\n",
    "    axes[0].set_title('Original Image Patch')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(mask_downsampled, cmap='Blues')\n",
    "    axes[1].set_title('Manual Labels (Ground Truth)')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(prediction_grid, cmap='Blues')\n",
    "    axes[2].set_title('DINOv2 Predictions')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # Show difference\n",
    "    difference = prediction_grid.astype(int) - mask_downsampled.astype(int)\n",
    "    axes[3].imshow(difference, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[3].set_title('Difference (Blue=Missed Water, Red=False Positive)')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✅ Classifier training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which DINOv2 features are most important for water detection\n",
    "if len(unique_labels) >= 2:\n",
    "    print(\"Analyzing feature importance...\")\n",
    "    \n",
    "    # Get feature importance from Random Forest\n",
    "    feature_importance = clf.feature_importances_\n",
    "    \n",
    "    # Plot top 20 most important features\n",
    "    top_features = np.argsort(feature_importance)[-20:]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(range(len(top_features)), feature_importance[top_features])\n",
    "    plt.ylabel('Feature Index')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 20 Most Important DINOv2 Features for Water Detection')\n",
    "    plt.yticks(range(len(top_features)), top_features)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Most important feature dimension: {top_features[-1]}\")\n",
    "    print(f\"Highest importance score: {feature_importance[top_features[-1]]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "**What we accomplished:**\n",
    "1. ✅ Loaded DINOv2 foundation model\n",
    "2. ✅ Loaded false color image and binary mask\n",
    "3. ✅ Extracted DINOv2 features from image patch\n",
    "4. ✅ Trained classifier on features + manual labels\n",
    "5. ✅ Evaluated performance on test patch\n",
    "\n",
    "**Next steps:**\n",
    "1. **Scale up**: Apply to larger image regions or full image\n",
    "2. **Add NDWI**: Combine DINOv2 features with NDWI values\n",
    "3. **Multiple patches**: Train on multiple patches for robustness\n",
    "4. **Apply to new images**: Use trained model on other dates\n",
    "5. **Compare with NDWI**: Evaluate vs your existing NDWI > 0.0 approach\n",
    "\n",
    "**Key insights:**\n",
    "- DINOv2 can learn visual patterns for water detection\n",
    "- Works at patch level (16x16 grid for 224x224 input)\n",
    "- Can be combined with spectral indices like NDWI\n",
    "- Foundation model requires minimal training data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:superlakes] *",
   "language": "python",
   "name": "conda-env-superlakes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6d4aec-25e1-4730-b749-b2c03ec9680f",
   "metadata": {},
   "source": [
    "# test from youtube tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83703a0-8b32-4df0-bc2b-a30a00af32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"my-login-token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7d7ec-2ec5-49ee-b12d-c8ee49322a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aca8090-7a66-4976-83b9-d04f913b31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers.image_utils import load_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51a074b7-5ce8-4b99-9435-cbbd6c98200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "image = load_image(\"/Users/varyabazilova/Desktop/glacial_lakes/super_lakes/dinov3_tryout/test_data/2021-09-04_fcc.tif\")\n",
    "feature_extractor = pipeline(\n",
    "    model = \"facebook/dinov3-vitb16-pretrain-lvd1689m\",\n",
    "    task = \"image-feature-extraction\",\n",
    ")\n",
    "\n",
    "features = feature_extractor(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01fdf738-09f0-4e29-89ba-569ab8ea2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afdb0c38-6d7c-4f58-82b6-865e36a76a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features type: <class 'list'>\n",
      "Features length: 1\n",
      "First element type: <class 'list'>\n",
      "Feature tensor shape: torch.Size([201, 768])\n",
      "Features array shape: (201, 768)\n"
     ]
    }
   ],
   "source": [
    "# Check the structure first\n",
    "print(f\"Features type: {type(features)}\")\n",
    "print(f\"Features length: {len(features)}\")\n",
    "print(f\"First element type: {type(features[0])}\")\n",
    "\n",
    "# Get the actual feature tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Extract the tensor from the nested structure\n",
    "feature_tensor = torch.tensor(features[0])\n",
    "print(f\"Feature tensor shape: {feature_tensor.shape}\")\n",
    "\n",
    "# Convert to numpy for analysis\n",
    "features_array = feature_tensor.numpy()\n",
    "print(f\"Features array shape: {features_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c37b36-0c61-4936-981a-a8aac8889ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files:   0%|                                                                                                                                                             | 0/6 [05:07<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = pipeline(\n",
    "  model=\"facebook/dinov3-vit7b16-pretrain-sat493m\",  # Satellite-trained version\n",
    "  task=\"image-feature-extraction\",\n",
    ")\n",
    "\n",
    "features = feature_extractor(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b43e81-250a-4af3-bbdd-69bc8d6b7ac9",
   "metadata": {},
   "source": [
    "# create patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a8d30-48b0-422f-affa-a9459a721697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "def create_patches(image_path, patch_size=224):\n",
    "  \"\"\"Cut image into small squares for analysis\"\"\"\n",
    "\n",
    "  # Load your satellite image\n",
    "  image = Image.open(image_path)\n",
    "  img_array = np.array(image)\n",
    "\n",
    "  patches = []\n",
    "  positions = []  # Remember where each patch came from\n",
    "\n",
    "  height, width = img_array.shape[:2]\n",
    "\n",
    "  # Cut image into patches\n",
    "  for y in range(0, height-patch_size, patch_size):\n",
    "      for x in range(0, width-patch_size, patch_size):\n",
    "          # Extract small square\n",
    "          patch = img_array[y:y+patch_size, x:x+patch_size]\n",
    "\n",
    "          patches.append(patch)\n",
    "          positions.append((y, x))  # Save position\n",
    "\n",
    "  return patches, positions, (height, width)\n",
    "\n",
    "# Use it on your image\n",
    "patches, positions, original_size = create_patches(\"/path/to/your/image.tif\")\n",
    "print(f\"Created {len(patches)} patches from your image\")\n",
    "\n",
    "# Now you can analyze each patch with DINOv3:\n",
    "\n",
    "# Analyze each patch\n",
    "patch_features = []\n",
    "for patch in patches:\n",
    "  patch_pil = Image.fromarray(patch)\n",
    "  features = feature_extractor(patch_pil)\n",
    "  patch_features.append(features[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:superlakes] *",
   "language": "python",
   "name": "conda-env-superlakes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

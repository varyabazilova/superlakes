{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DINOv3 Lake Detection - Inference Notebook for Google Colab\n",
    "\n",
    "Use your trained model to detect lakes in new satellite images\n",
    "\n",
    "**What this notebook does:**\n",
    "1. Loads your trained DINOv3 + U-Net model\n",
    "2. Processes new satellite images to detect lakes\n",
    "3. Applies boundary constraints (glacier areas only)\n",
    "4. Saves results and creates visualizations\n",
    "\n",
    "**Requirements:**\n",
    "- Your trained model file (saved from training notebook)\n",
    "- New satellite images to process\n",
    "- Optional: Boundary shapefile for glacier areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install required packages\n",
    "print(\"üì¶ Installing required packages...\")\n",
    "!pip install torch torchvision transformers\n",
    "!pip install rasterio geopandas opencv-python\n",
    "!pip install scikit-image matplotlib\n",
    "\n",
    "print(\"‚úÖ All packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import all necessary libraries\n",
    "print(\"üìö Importing libraries...\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "from rasterio.features import geometry_mask\n",
    "from transformers import AutoModel\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è Using device: {device}\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Mount Google Drive to access your saved model and images\n",
    "print(\"üíæ Mounting Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Google Drive mounted!\")\n",
    "\n",
    "# Set your file paths here (UPDATE THESE PATHS)\n",
    "MODEL_PATH = '/content/drive/MyDrive/superlakes/models/dinov3_lake_inference_ready.pth'\n",
    "SHAPEFILE_PATH = '/content/drive/MyDrive/superlakes/vectors/clip_by_glacier.shp'\n",
    "\n",
    "# Path to new image you want to process\n",
    "NEW_IMAGE_PATH = '/content/drive/MyDrive/superlakes/new_satellite_image.tif'\n",
    "\n",
    "# Where to save results\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/superlakes/results/'\n",
    "\n",
    "print(f\"üìÅ Model path: {MODEL_PATH}\")\n",
    "print(f\"üó∫Ô∏è Shapefile path: {SHAPEFILE_PATH}\")\n",
    "print(f\"üñºÔ∏è New image path: {NEW_IMAGE_PATH}\")\n",
    "print(f\"üíæ Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define the model architecture (same as training)\n",
    "print(\"üèóÔ∏è Setting up model architecture...\")\n",
    "\n",
    "class DynamicUNetDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the 'brain' that converts DINOv3 features into lake predictions\n",
    "    Think of it as: DINOv3 sees the image ‚Üí Decoder decides what's water\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim=768, num_classes=1, target_size=224):\n",
    "        super(DynamicUNetDecoder, self).__init__()\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # Series of layers that gradually convert features to water/no-water decisions\n",
    "        self.conv1 = nn.Conv2d(feature_dim, 512, kernel_size=3, padding=1)  # 768 ‚Üí 512 features\n",
    "        self.conv2 = nn.Conv2d(512, 256, kernel_size=3, padding=1)          # 512 ‚Üí 256 features  \n",
    "        self.conv3 = nn.Conv2d(256, 128, kernel_size=3, padding=1)          # 256 ‚Üí 128 features\n",
    "        self.conv4 = nn.Conv2d(128, 64, kernel_size=3, padding=1)           # 128 ‚Üí 64 features\n",
    "        self.final = nn.Conv2d(64, num_classes, kernel_size=1)              # 64 ‚Üí 1 (water probability)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)    # Activation function\n",
    "        self.sigmoid = nn.Sigmoid()          # Converts output to 0-1 probability\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Process features through each layer\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.final(x)\n",
    "        \n",
    "        # Resize to exact target size (224x224)\n",
    "        x = nn.functional.interpolate(x, size=(self.target_size, self.target_size), \n",
    "                                    mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Convert to probabilities (0 = no water, 1 = definitely water)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class DINOv3UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete model: DINOv3 (sees images) + U-Net (decides what's water)\n",
    "    This is the same architecture you trained in your main notebook\n",
    "    \"\"\"\n",
    "    def __init__(self, dinov3_model_name=\"facebook/dinov3-vitb16-pretrain-lvd1689m\"):\n",
    "        super(DINOv3UNet, self).__init__()\n",
    "        \n",
    "        # Load DINOv3 - this is the 'eyes' that extract features from satellite images\n",
    "        print(f\"   Loading DINOv3 model: {dinov3_model_name}\")\n",
    "        self.dinov3 = AutoModel.from_pretrained(dinov3_model_name)\n",
    "        \n",
    "        # Freeze DINOv3 (we don't change its weights, just use its features)\n",
    "        for param in self.dinov3.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Add our trained decoder (this is what we actually trained)\n",
    "        self.decoder = DynamicUNetDecoder(feature_dim=768, target_size=224)\n",
    "        \n",
    "        print(\"   ‚úÖ Model architecture created!\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass: Image ‚Üí DINOv3 features ‚Üí U-Net decoder ‚Üí Water probability\n",
    "        \"\"\"\n",
    "        with torch.no_grad():  # Don't compute gradients for DINOv3 (saves memory)\n",
    "            # Get features from DINOv3\n",
    "            features = self.dinov3(x).last_hidden_state\n",
    "            \n",
    "            # Remove the first token (CLS token) - we only want patch features\n",
    "            patch_features = features[:, 1:]\n",
    "            \n",
    "            batch_size, num_patches, feature_dim = patch_features.shape\n",
    "            \n",
    "            # Figure out spatial arrangement (DINOv3 outputs patches in a sequence)\n",
    "            h = int(num_patches**0.5)  # Assume roughly square arrangement\n",
    "            w = h\n",
    "            \n",
    "            # Handle case where patches don't form perfect square\n",
    "            if h * w != num_patches:\n",
    "                needed_patches = h * w\n",
    "                if needed_patches > num_patches:\n",
    "                    # Pad with zeros if we need more patches\n",
    "                    padding = torch.zeros(batch_size, needed_patches - num_patches, \n",
    "                                        feature_dim, device=patch_features.device)\n",
    "                    patch_features = torch.cat([patch_features, padding], dim=1)\n",
    "                else:\n",
    "                    # Truncate if we have too many patches\n",
    "                    patch_features = patch_features[:, :needed_patches]\n",
    "            \n",
    "            # Reshape from sequence to 2D feature map\n",
    "            feature_map = patch_features.reshape(batch_size, h, w, feature_dim)\n",
    "            feature_map = feature_map.permute(0, 3, 1, 2)  # Change to (batch, features, height, width)\n",
    "        \n",
    "        # Generate water probability mask using our trained decoder\n",
    "        water_mask = self.decoder(feature_map)\n",
    "        return water_mask\n",
    "\n",
    "print(\"‚úÖ Model architecture defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load your trained model\n",
    "print(\"üîÑ Loading your trained model...\")\n",
    "\n",
    "# Check if model file exists\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"‚ùå Model file not found: {MODEL_PATH}\")\n",
    "    print(\"   Please check the path and make sure you saved the model correctly!\")\n",
    "else:\n",
    "    # Load the saved model information\n",
    "    print(f\"   Loading from: {MODEL_PATH}\")\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "    \n",
    "    # Create the model architecture\n",
    "    model = DINOv3UNet().to(device)\n",
    "    \n",
    "    # Load the trained weights into the model\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Set to evaluation mode (important for inference)\n",
    "    model.eval()\n",
    "    \n",
    "    # Show what configuration was used during training\n",
    "    if 'model_config' in checkpoint:\n",
    "        config = checkpoint['model_config']\n",
    "        print(f\"   ‚úÖ Model loaded successfully!\")\n",
    "        print(f\"   Training configuration:\")\n",
    "        print(f\"     - Patch size: {config.get('patch_size', 'unknown')}\")\n",
    "        print(f\"     - Stride: {config.get('stride', 'unknown')}\")\n",
    "        print(f\"     - DINOv3 model: {config.get('dinov3_model', 'unknown')}\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Model loaded successfully (basic version)!\")\n",
    "\n",
    "print(\"‚úÖ Model ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create helper functions for processing images\n",
    "print(\"üõ†Ô∏è Setting up helper functions...\")\n",
    "\n",
    "def create_boundary_mask(image_path, shapefile_path):\n",
    "    \"\"\"\n",
    "    Create a mask from your shapefile to only analyze glacier areas\n",
    "    This is the same boundary constraint you used during training\n",
    "    \"\"\"\n",
    "    print(f\"   üìê Creating boundary mask from shapefile...\")\n",
    "    \n",
    "    if not os.path.exists(shapefile_path):\n",
    "        print(f\"   ‚ö†Ô∏è Shapefile not found: {shapefile_path}\")\n",
    "        print(\"   Will process entire image without boundary constraint\")\n",
    "        return None\n",
    "    \n",
    "    # Load the shapefile (your glacier boundary)\n",
    "    shapefile = gpd.read_file(shapefile_path)\n",
    "    print(f\"   Found {len(shapefile)} polygon(s) in shapefile\")\n",
    "    \n",
    "    # Load image to get its coordinate system and dimensions\n",
    "    with rasterio.open(image_path) as src:\n",
    "        image_crs = src.crs\n",
    "        image_transform = src.transform\n",
    "        image_shape = (src.height, src.width)\n",
    "    \n",
    "    print(f\"   Image CRS: {image_crs}\")\n",
    "    print(f\"   Shapefile CRS: {shapefile.crs}\")\n",
    "    \n",
    "    # Make sure shapefile and image use same coordinate system\n",
    "    if shapefile.crs != image_crs:\n",
    "        print(f\"   üîÑ Reprojecting shapefile to match image...\")\n",
    "        shapefile = shapefile.to_crs(image_crs)\n",
    "    \n",
    "    # Create binary mask: 1 = inside glacier boundary, 0 = outside\n",
    "    boundary_mask = ~geometry_mask(\n",
    "        shapefile.geometry,\n",
    "        transform=image_transform,\n",
    "        invert=False,\n",
    "        out_shape=image_shape\n",
    "    )\n",
    "    \n",
    "    pixels_inside = boundary_mask.sum()\n",
    "    total_pixels = boundary_mask.size\n",
    "    percentage = pixels_inside / total_pixels * 100\n",
    "    \n",
    "    print(f\"   ‚úÖ Boundary mask created!\")\n",
    "    print(f\"   Glacier area: {pixels_inside:,} pixels ({percentage:.1f}% of image)\")\n",
    "    \n",
    "    return boundary_mask.astype(np.uint8)\n",
    "\n",
    "def setup_image_transform():\n",
    "    \"\"\"\n",
    "    Create the same image preprocessing used during training\n",
    "    This normalizes images the way DINOv3 expects them\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        # These normalization values are standard for DINOv3\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "print(\"‚úÖ Helper functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Main prediction function\n",
    "print(\"üéØ Setting up main prediction function...\")\n",
    "\n",
    "def predict_lakes_in_image(image_path, shapefile_path=None, patch_size=16, stride=8, save_result=True):\n",
    "    \"\"\"\n",
    "    Apply your trained model to detect lakes in a new satellite image\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: Path to satellite image\n",
    "    - shapefile_path: Path to boundary shapefile (optional)\n",
    "    - patch_size: Size of patches to process (use same as training)\n",
    "    - stride: Step size between patches (use same as training)\n",
    "    - save_result: Whether to save the result\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üñºÔ∏è Processing image: {os.path.basename(image_path)}\")\n",
    "    \n",
    "    # Step 7a: Load the satellite image\n",
    "    print(\"   üìÇ Loading satellite image...\")\n",
    "    with rasterio.open(image_path) as src:\n",
    "        image = src.read()  # Read all bands\n",
    "        image = np.transpose(image, (1, 2, 0))  # Change from (bands, height, width) to (height, width, bands)\n",
    "        \n",
    "        # Take only RGB channels (first 3 bands)\n",
    "        image_rgb = image[:,:,:3].astype(np.uint8)\n",
    "        \n",
    "        # Save image info for later (to save results with same projection)\n",
    "        profile = src.profile.copy()\n",
    "    \n",
    "    height, width = image_rgb.shape[:2]\n",
    "    print(f\"   Image size: {width} x {height} pixels\")\n",
    "    print(f\"   Using RGB channels: {image_rgb.shape}\")\n",
    "    \n",
    "    # Step 7b: Create boundary mask if shapefile provided\n",
    "    boundary_mask = None\n",
    "    if shapefile_path:\n",
    "        boundary_mask = create_boundary_mask(image_path, shapefile_path)\n",
    "    \n",
    "    # Step 7c: Set up for patch processing\n",
    "    print(f\"   üîÑ Processing with {patch_size}x{patch_size} patches, stride {stride}...\")\n",
    "    \n",
    "    # Create arrays to accumulate predictions\n",
    "    full_mask = np.zeros((height, width), dtype=np.float32)  # Final prediction\n",
    "    count_mask = np.zeros((height, width), dtype=np.float32)  # Count of overlapping patches\n",
    "    \n",
    "    # Set up image preprocessing\n",
    "    transform = setup_image_transform()\n",
    "    \n",
    "    patches_processed = 0\n",
    "    patches_skipped = 0\n",
    "    \n",
    "    # Step 7d: Process image patch by patch\n",
    "    with torch.no_grad():  # Don't compute gradients (saves memory)\n",
    "        \n",
    "        # Loop through all possible patch positions\n",
    "        for y in range(0, height - patch_size + 1, stride):\n",
    "            for x in range(0, width - patch_size + 1, stride):\n",
    "                \n",
    "                # Check if patch center is inside boundary (if boundary provided)\n",
    "                if boundary_mask is not None:\n",
    "                    center_y = y + patch_size // 2\n",
    "                    center_x = x + patch_size // 2\n",
    "                    \n",
    "                    if boundary_mask[center_y, center_x] == 0:\n",
    "                        patches_skipped += 1\n",
    "                        continue  # Skip patches outside glacier boundary\n",
    "                \n",
    "                # Extract small patch from image\n",
    "                small_patch = image_rgb[y:y+patch_size, x:x+patch_size, :3]\n",
    "                \n",
    "                # Resize to 224x224 (what DINOv3 expects)\n",
    "                patch_224 = cv2.resize(small_patch, (224, 224))\n",
    "                \n",
    "                # Preprocess patch (normalize, convert to tensor)\n",
    "                patch_tensor = transform(patch_224).unsqueeze(0).to(device)\n",
    "                \n",
    "                # Run model prediction (gets 224x224 output)\n",
    "                pred_224 = model(patch_tensor).squeeze().cpu().numpy()\n",
    "                \n",
    "                # Resize prediction back to original patch size\n",
    "                pred_small = cv2.resize(pred_224, (patch_size, patch_size))\n",
    "                \n",
    "                # Add prediction to full image (accumulate overlapping patches)\n",
    "                full_mask[y:y+patch_size, x:x+patch_size] += pred_small\n",
    "                count_mask[y:y+patch_size, x:x+patch_size] += 1\n",
    "                \n",
    "                patches_processed += 1\n",
    "                \n",
    "                # Show progress every 1000 patches\n",
    "                if patches_processed % 1000 == 0:\n",
    "                    print(f\"      Processed {patches_processed} patches...\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Patch processing complete!\")\n",
    "    print(f\"   Processed: {patches_processed} patches\")\n",
    "    print(f\"   Skipped: {patches_skipped} patches (outside boundary)\")\n",
    "    \n",
    "    # Step 7e: Average overlapping predictions\n",
    "    print(\"   üßÆ Averaging overlapping predictions...\")\n",
    "    final_mask = np.divide(full_mask, count_mask, out=np.zeros_like(full_mask), where=count_mask!=0)\n",
    "    \n",
    "    # Apply boundary mask to final result\n",
    "    if boundary_mask is not None:\n",
    "        final_mask = final_mask * boundary_mask\n",
    "    \n",
    "    # Step 7f: Calculate statistics\n",
    "    water_pixels = (final_mask > 0.5).sum()  # Count pixels with >50% water probability\n",
    "    total_pixels = final_mask.size\n",
    "    coverage_percent = water_pixels / total_pixels * 100\n",
    "    \n",
    "    if boundary_mask is not None:\n",
    "        analysis_pixels = boundary_mask.sum()\n",
    "        coverage_of_analysis_area = water_pixels / analysis_pixels * 100\n",
    "        print(f\"   üìä Results:\")\n",
    "        print(f\"     Water pixels: {water_pixels:,}\")\n",
    "        print(f\"     Coverage of total image: {coverage_percent:.2f}%\")\n",
    "        print(f\"     Coverage of analysis area: {coverage_of_analysis_area:.2f}%\")\n",
    "    else:\n",
    "        print(f\"   üìä Results:\")\n",
    "        print(f\"     Water pixels: {water_pixels:,}\")\n",
    "        print(f\"     Coverage: {coverage_percent:.2f}%\")\n",
    "    \n",
    "    # Step 7g: Save result if requested\n",
    "    if save_result:\n",
    "        # Create output filename\n",
    "        image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        output_filename = f\"{image_name}_lake_prediction.tif\"\n",
    "        output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
    "        \n",
    "        # Create output directory if needed\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "        \n",
    "        # Update profile for single-band float output\n",
    "        profile.update({\n",
    "            'dtype': rasterio.float32,\n",
    "            'count': 1,\n",
    "            'nodata': 0\n",
    "        })\n",
    "        \n",
    "        # Save as GeoTIFF\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            dst.write(final_mask.astype('float32'), 1)\n",
    "        \n",
    "        print(f\"   üíæ Saved result: {output_path}\")\n",
    "    \n",
    "    return final_mask, water_pixels, coverage_percent\n",
    "\n",
    "print(\"‚úÖ Prediction function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Visualize results\n",
    "print(\"üé® Setting up visualization function...\")\n",
    "\n",
    "def visualize_prediction(image_path, predicted_mask, save_plot=True):\n",
    "    \"\"\"\n",
    "    Create a nice visualization comparing original image with prediction\n",
    "    \"\"\"\n",
    "    print(\"   üñºÔ∏è Creating visualization...\")\n",
    "    \n",
    "    # Load original image for display\n",
    "    with rasterio.open(image_path) as src:\n",
    "        image = src.read()\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        image_rgb = image[:,:,:3].astype(np.uint8)\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(image_rgb)\n",
    "    axes[0].set_title('Original Satellite Image', fontsize=14)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Prediction probabilities\n",
    "    im1 = axes[1].imshow(predicted_mask, cmap='Blues', vmin=0, vmax=1)\n",
    "    axes[1].set_title('Lake Probability\\n(0=No Water, 1=Definitely Water)', fontsize=14)\n",
    "    axes[1].axis('off')\n",
    "    plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Binary prediction overlay\n",
    "    axes[2].imshow(image_rgb)\n",
    "    binary_mask = predicted_mask > 0.5\n",
    "    axes[2].imshow(binary_mask, cmap='Reds', alpha=0.6)\n",
    "    axes[2].set_title('Detected Lakes (Red Overlay)\\nThreshold: 50% Confidence', fontsize=14)\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plot:\n",
    "        image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        plot_filename = f\"{image_name}_visualization.png\"\n",
    "        plot_path = os.path.join(OUTPUT_DIR, plot_filename)\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"   üíæ Saved visualization: {plot_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    water_pixels = (predicted_mask > 0.5).sum()\n",
    "    total_pixels = predicted_mask.size\n",
    "    coverage = water_pixels / total_pixels * 100\n",
    "    \n",
    "    print(f\"   üìä Summary:\")\n",
    "    print(f\"     - Water pixels detected: {water_pixels:,}\")\n",
    "    print(f\"     - Coverage: {coverage:.2f}%\")\n",
    "    print(f\"     - Confidence range: {predicted_mask.min():.3f} to {predicted_mask.max():.3f}\")\n",
    "\n",
    "print(\"‚úÖ Visualization function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: RUN THE INFERENCE! üöÄ\n",
    "print(\"üöÄ Starting lake detection inference...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if input image exists\n",
    "if not os.path.exists(NEW_IMAGE_PATH):\n",
    "    print(f\"‚ùå Image not found: {NEW_IMAGE_PATH}\")\n",
    "    print(\"   Please update NEW_IMAGE_PATH with the correct path to your satellite image\")\n",
    "else:\n",
    "    # Run the prediction\n",
    "    predicted_mask, water_pixels, coverage = predict_lakes_in_image(\n",
    "        image_path=NEW_IMAGE_PATH,\n",
    "        shapefile_path=SHAPEFILE_PATH,  # Set to None if you don't want boundary constraint\n",
    "        patch_size=16,                  # Same as training\n",
    "        stride=8,                       # Same as training\n",
    "        save_result=True\n",
    "    )\n",
    "    \n",
    "    # Show the results\n",
    "    visualize_prediction(NEW_IMAGE_PATH, predicted_mask, save_plot=True)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üéâ INFERENCE COMPLETE!\")\n",
    "    print(f\"‚úÖ Successfully detected {water_pixels:,} water pixels ({coverage:.2f}% coverage)\")\n",
    "    print(f\"üíæ Results saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: (Optional) Process multiple images\n",
    "print(\"üìÅ Optional: Process multiple images at once\")\n",
    "print(\"Uncomment and modify the code below to process a folder of images\")\n",
    "\n",
    "\"\"\"\n",
    "# Example: Process all .tif files in a directory\n",
    "input_directory = '/content/drive/MyDrive/superlakes/many_images/'\n",
    "output_directory = '/content/drive/MyDrive/superlakes/batch_results/'\n",
    "\n",
    "# Get list of all TIFF files\n",
    "import glob\n",
    "image_files = glob.glob(os.path.join(input_directory, '*.tif'))\n",
    "\n",
    "print(f\"Found {len(image_files)} images to process\")\n",
    "\n",
    "# Process each image\n",
    "results = []\n",
    "for i, image_path in enumerate(image_files, 1):\n",
    "    print(f\"\\n--- Processing {i}/{len(image_files)}: {os.path.basename(image_path)} ---\")\n",
    "    \n",
    "    try:\n",
    "        # Predict lakes\n",
    "        pred_mask, water_pix, coverage = predict_lakes_in_image(\n",
    "            image_path=image_path,\n",
    "            shapefile_path=SHAPEFILE_PATH,\n",
    "            patch_size=16,\n",
    "            stride=8,\n",
    "            save_result=True\n",
    "        )\n",
    "        \n",
    "        # Record results\n",
    "        results.append({\n",
    "            'image': os.path.basename(image_path),\n",
    "            'water_pixels': water_pix,\n",
    "            'coverage_percent': coverage,\n",
    "            'status': 'success'\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {os.path.basename(image_path)}: {e}\")\n",
    "        results.append({\n",
    "            'image': os.path.basename(image_path),\n",
    "            'error': str(e),\n",
    "            'status': 'failed'\n",
    "        })\n",
    "\n",
    "# Save summary\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "summary_path = os.path.join(output_directory, 'batch_processing_summary.csv')\n",
    "df.to_csv(summary_path, index=False)\n",
    "\n",
    "print(f\"\\nüéâ Batch processing complete!\")\n",
    "print(f\"Successfully processed: {len(df[df['status'] == 'success'])}/{len(df)} images\")\n",
    "print(f\"Summary saved: {summary_path}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ Inference notebook ready!\")\n",
    "print(\"\\nüí° To use this notebook:\")\n",
    "print(\"1. Update the file paths in Step 3\")\n",
    "print(\"2. Run all cells in order\")\n",
    "print(\"3. Your results will be saved to Google Drive\")\n",
    "print(\"4. Check the visualization to see how well it worked!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DINOv3 Lake Detection - SIMPLE Inference\n",
    "\n",
    "**Super simple workflow:**\n",
    "1. Load your complete trained model\n",
    "2. Point it at a new satellite image  \n",
    "3. Get lake predictions!\n",
    "\n",
    "**No need to redefine model architecture - everything is saved!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install packages and setup\n",
    "print(\"üì¶ Installing packages...\")\n",
    "!pip install torch torchvision transformers\n",
    "!pip install rasterio geopandas opencv-python matplotlib\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "from rasterio.features import geometry_mask\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set your file paths (ONLY THING YOU NEED TO UPDATE!)\n",
    "\n",
    "# Your saved complete model\n",
    "MODEL_PATH = '/content/drive/MyDrive/superlakes/models/dinov3_lake_detection_complete.pth'\n",
    "\n",
    "# New image to process\n",
    "NEW_IMAGE_PATH = '/content/drive/MyDrive/superlakes/new_satellite_image.tif'\n",
    "\n",
    "# Where to save results\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/superlakes/simple_results/'\n",
    "\n",
    "print(f\"üìÅ Model: {MODEL_PATH}\")\n",
    "print(f\"üñºÔ∏è Image: {NEW_IMAGE_PATH}\")\n",
    "print(f\"üíæ Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load your trained model (SUPER SIMPLE!)\n",
    "print(\"üîÑ Loading your trained model...\")\n",
    "\n",
    "# Load everything we saved\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "\n",
    "# Extract the complete model\n",
    "model = checkpoint['complete_model'].to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Get training configuration\n",
    "patch_size = checkpoint['patch_size']\n",
    "stride = checkpoint['stride']\n",
    "shapefile_path = checkpoint['shapefile_path']\n",
    "\n",
    "print(f\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"   Training patch size: {patch_size}\")\n",
    "print(f\"   Training stride: {stride}\")\n",
    "print(f\"   Boundary shapefile: {os.path.basename(shapefile_path)}\")\n",
    "print(f\"   Training info: {checkpoint['training_info']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Simple helper functions\n",
    "\n",
    "def create_boundary_mask(image_path, shapefile_path):\n",
    "    \"\"\"Create glacier boundary mask\"\"\"\n",
    "    if not os.path.exists(shapefile_path):\n",
    "        print(f\"‚ö†Ô∏è Shapefile not found, processing entire image\")\n",
    "        return None\n",
    "    \n",
    "    # Load shapefile and image info\n",
    "    shapefile = gpd.read_file(shapefile_path)\n",
    "    \n",
    "    with rasterio.open(image_path) as src:\n",
    "        image_crs = src.crs\n",
    "        image_transform = src.transform\n",
    "        image_shape = (src.height, src.width)\n",
    "    \n",
    "    # Reproject if needed\n",
    "    if shapefile.crs != image_crs:\n",
    "        shapefile = shapefile.to_crs(image_crs)\n",
    "    \n",
    "    # Create mask\n",
    "    boundary_mask = ~geometry_mask(\n",
    "        shapefile.geometry,\n",
    "        transform=image_transform,\n",
    "        invert=False,\n",
    "        out_shape=image_shape\n",
    "    )\n",
    "    \n",
    "    pixels_inside = boundary_mask.sum()\n",
    "    percentage = pixels_inside / boundary_mask.size * 100\n",
    "    print(f\"   Glacier area: {pixels_inside:,} pixels ({percentage:.1f}%)\")\n",
    "    \n",
    "    return boundary_mask.astype(np.uint8)\n",
    "\n",
    "def setup_transforms():\n",
    "    \"\"\"Image preprocessing for DINOv3\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "print(\"‚úÖ Helper functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: THE MAIN FUNCTION - Detect lakes in new image\n",
    "\n",
    "def detect_lakes(image_path, model, patch_size, stride, shapefile_path=None):\n",
    "    \"\"\"Detect lakes in a satellite image - SIMPLE VERSION!\"\"\"\n",
    "    \n",
    "    print(f\"üñºÔ∏è Processing: {os.path.basename(image_path)}\")\n",
    "    \n",
    "    # Load image\n",
    "    with rasterio.open(image_path) as src:\n",
    "        image = src.read()\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        image_rgb = image[:,:,:3].astype(np.uint8)\n",
    "        profile = src.profile.copy()\n",
    "    \n",
    "    height, width = image_rgb.shape[:2]\n",
    "    print(f\"   Image size: {width} x {height}\")\n",
    "    \n",
    "    # Create boundary mask\n",
    "    boundary_mask = None\n",
    "    if shapefile_path:\n",
    "        boundary_mask = create_boundary_mask(image_path, shapefile_path)\n",
    "    \n",
    "    # Setup for processing\n",
    "    full_mask = np.zeros((height, width), dtype=np.float32)\n",
    "    count_mask = np.zeros((height, width), dtype=np.float32)\n",
    "    transform = setup_transforms()\n",
    "    \n",
    "    patches_processed = 0\n",
    "    patches_skipped = 0\n",
    "    \n",
    "    print(f\"   Processing with {patch_size}x{patch_size} patches...\")\n",
    "    \n",
    "    # Process patches\n",
    "    with torch.no_grad():\n",
    "        for y in range(0, height - patch_size + 1, stride):\n",
    "            for x in range(0, width - patch_size + 1, stride):\n",
    "                \n",
    "                # Check boundary constraint\n",
    "                if boundary_mask is not None:\n",
    "                    center_y = y + patch_size // 2\n",
    "                    center_x = x + patch_size // 2\n",
    "                    if boundary_mask[center_y, center_x] == 0:\n",
    "                        patches_skipped += 1\n",
    "                        continue\n",
    "                \n",
    "                # Extract and process patch\n",
    "                small_patch = image_rgb[y:y+patch_size, x:x+patch_size, :3]\n",
    "                patch_224 = cv2.resize(small_patch, (224, 224))\n",
    "                patch_tensor = transform(patch_224).unsqueeze(0).to(device)\n",
    "                \n",
    "                # Model prediction\n",
    "                pred_224 = model(patch_tensor).squeeze().cpu().numpy()\n",
    "                pred_small = cv2.resize(pred_224, (patch_size, patch_size))\n",
    "                \n",
    "                # Accumulate\n",
    "                full_mask[y:y+patch_size, x:x+patch_size] += pred_small\n",
    "                count_mask[y:y+patch_size, x:x+patch_size] += 1\n",
    "                \n",
    "                patches_processed += 1\n",
    "                if patches_processed % 1000 == 0:\n",
    "                    print(f\"      {patches_processed} patches processed...\")\n",
    "    \n",
    "    # Average overlapping predictions\n",
    "    final_mask = np.divide(full_mask, count_mask, out=np.zeros_like(full_mask), where=count_mask!=0)\n",
    "    \n",
    "    # Apply boundary constraint\n",
    "    if boundary_mask is not None:\n",
    "        final_mask = final_mask * boundary_mask\n",
    "    \n",
    "    # Statistics\n",
    "    water_pixels = (final_mask > 0.5).sum()\n",
    "    coverage = water_pixels / final_mask.size * 100\n",
    "    \n",
    "    print(f\"   ‚úÖ Complete! {patches_processed} patches processed, {patches_skipped} skipped\")\n",
    "    print(f\"   üìä Water detected: {water_pixels:,} pixels ({coverage:.2f}%)\")\n",
    "    \n",
    "    return final_mask, water_pixels, coverage, profile\n",
    "\n",
    "print(\"‚úÖ Main detection function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: RUN LAKE DETECTION! üöÄ\n",
    "\n",
    "print(\"üöÄ Starting lake detection...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.exists(NEW_IMAGE_PATH):\n",
    "    print(f\"‚ùå Image not found: {NEW_IMAGE_PATH}\")\n",
    "else:\n",
    "    # Run detection\n",
    "    predicted_mask, water_pixels, coverage, profile = detect_lakes(\n",
    "        image_path=NEW_IMAGE_PATH,\n",
    "        model=model,\n",
    "        patch_size=patch_size,  # From loaded model config\n",
    "        stride=stride,          # From loaded model config  \n",
    "        shapefile_path=shapefile_path  # From loaded model config\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"üéâ DETECTION COMPLETE!\")\n",
    "    print(f\"‚úÖ Found {water_pixels:,} water pixels ({coverage:.2f}% coverage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Save results and create visualization\n",
    "\n",
    "print(\"üíæ Saving results...\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Save prediction as GeoTIFF\n",
    "image_name = os.path.splitext(os.path.basename(NEW_IMAGE_PATH))[0]\n",
    "output_path = os.path.join(OUTPUT_DIR, f\"{image_name}_lakes.tif\")\n",
    "\n",
    "profile.update({\n",
    "    'dtype': rasterio.float32,\n",
    "    'count': 1,\n",
    "    'nodata': 0\n",
    "})\n",
    "\n",
    "with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "    dst.write(predicted_mask.astype('float32'), 1)\n",
    "\n",
    "print(f\"‚úÖ Saved prediction: {output_path}\")\n",
    "\n",
    "# Create visualization\n",
    "print(\"üé® Creating visualization...\")\n",
    "\n",
    "# Load original image for display\n",
    "with rasterio.open(NEW_IMAGE_PATH) as src:\n",
    "    image = src.read()\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    image_rgb = image[:,:,:3].astype(np.uint8)\n",
    "\n",
    "# Create 3-panel plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(image_rgb)\n",
    "axes[0].set_title('Original Satellite Image', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Probability map\n",
    "im1 = axes[1].imshow(predicted_mask, cmap='Blues', vmin=0, vmax=1)\n",
    "axes[1].set_title('Lake Probability\\n(0=No Water, 1=Water)', fontsize=14)\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Binary detection overlay\n",
    "axes[2].imshow(image_rgb)\n",
    "binary_mask = predicted_mask > 0.5\n",
    "axes[2].imshow(binary_mask, cmap='Reds', alpha=0.6)\n",
    "axes[2].set_title('Detected Lakes (Red)', fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "plot_path = os.path.join(OUTPUT_DIR, f\"{image_name}_visualization.png\")\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Saved visualization: {plot_path}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\nüìä FINAL SUMMARY:\")\n",
    "print(f\"   üñºÔ∏è Image processed: {os.path.basename(NEW_IMAGE_PATH)}\")\n",
    "print(f\"   üíß Water pixels: {water_pixels:,}\")\n",
    "print(f\"   üìä Coverage: {coverage:.2f}%\")\n",
    "print(f\"   üéØ Confidence range: {predicted_mask.min():.3f} to {predicted_mask.max():.3f}\")\n",
    "print(f\"   üíæ Results saved to: {OUTPUT_DIR}\")\n",
    "print(\"\\nüéâ All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: (Optional) Process multiple images at once\n",
    "\n",
    "print(\"üìÅ OPTIONAL: Batch process multiple images\")\n",
    "print(\"Uncomment the code below to process a folder of images:\")\n",
    "\n",
    "\"\"\"\n",
    "# Batch processing example\n",
    "import glob\n",
    "\n",
    "# Directory with many images\n",
    "batch_input_dir = '/content/drive/MyDrive/superlakes/many_images/'\n",
    "batch_output_dir = '/content/drive/MyDrive/superlakes/batch_results/'\n",
    "\n",
    "# Find all images\n",
    "image_files = glob.glob(os.path.join(batch_input_dir, '*.tif'))\n",
    "print(f\"Found {len(image_files)} images to process\")\n",
    "\n",
    "# Process each one\n",
    "results = []\n",
    "for i, img_path in enumerate(image_files, 1):\n",
    "    print(f\"\\n--- {i}/{len(image_files)}: {os.path.basename(img_path)} ---\")\n",
    "    \n",
    "    try:\n",
    "        # Detect lakes\n",
    "        pred_mask, water_pix, cov, prof = detect_lakes(\n",
    "            img_path, model, patch_size, stride, shapefile_path\n",
    "        )\n",
    "        \n",
    "        # Save result\n",
    "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        out_path = os.path.join(batch_output_dir, f\"{name}_lakes.tif\")\n",
    "        \n",
    "        os.makedirs(batch_output_dir, exist_ok=True)\n",
    "        prof.update({'dtype': rasterio.float32, 'count': 1, 'nodata': 0})\n",
    "        \n",
    "        with rasterio.open(out_path, 'w', **prof) as dst:\n",
    "            dst.write(pred_mask.astype('float32'), 1)\n",
    "        \n",
    "        results.append({\n",
    "            'image': name,\n",
    "            'water_pixels': water_pix,\n",
    "            'coverage_percent': cov,\n",
    "            'status': 'success'\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        results.append({\n",
    "            'image': os.path.basename(img_path),\n",
    "            'error': str(e),\n",
    "            'status': 'failed'\n",
    "        })\n",
    "\n",
    "# Save summary\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "summary_path = os.path.join(batch_output_dir, 'batch_summary.csv')\n",
    "df.to_csv(summary_path, index=False)\n",
    "\n",
    "print(f\"\\nüéâ Batch complete! {len(df[df['status'] == 'success'])}/{len(df)} successful\")\n",
    "print(f\"Summary: {summary_path}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüí° Usage Summary:\")\n",
    "print(\"1. Update paths in Step 2\")\n",
    "print(\"2. Run all cells\")\n",
    "print(\"3. Get results!\")\n",
    "print(\"\\n‚ú® That's it - super simple! ‚ú®\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
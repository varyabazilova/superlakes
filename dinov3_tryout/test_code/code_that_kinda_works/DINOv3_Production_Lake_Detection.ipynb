{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the complete pipeline\n",
    "# This will test all hyperparameter combinations and find the best model\n",
    "\n",
    "results, summary = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the Pipeline\n",
    "\n",
    "**Run the cell below to start the complete hyperparameter search and evaluation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution workflow\n",
    "def main():\n",
    "    \"\"\"Main function to run the complete hyperparameter search and evaluation\"\"\"\n",
    "    print(f\"üöÄ Starting DINOv3 Lake Detection - Production Pipeline\")\n",
    "    print(f\"=\" * 60)\n",
    "    \n",
    "    # Save configuration\n",
    "    config_path = os.path.join(config.output_dir, \"config.json\")\n",
    "    config.save_config(config_path)\n",
    "    \n",
    "    # Run complete hyperparameter search\n",
    "    all_results = run_full_hyperparameter_search(image_rgb, mask_binary, boundary_mask, config)\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"‚ùå No successful experiments completed\")\n",
    "        return\n",
    "    \n",
    "    # Create results summary\n",
    "    summary_df = create_results_summary(all_results)\n",
    "    \n",
    "    # Save summary\n",
    "    summary_path = os.path.join(config.output_dir, \"experiments_summary.csv\")\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"\\\\n‚úÖ Experiments summary saved: {summary_path}\")\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\\\nüìä EXPERIMENTS SUMMARY:\")\n",
    "    print(summary_df.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # Find best model\n",
    "    best_experiment = summary_df.iloc[0]\n",
    "    print(f\"\\\\nüèÜ BEST MODEL:\")\n",
    "    print(f\"   Experiment: {best_experiment['Experiment']}\")\n",
    "    print(f\"   Patch Size: {best_experiment['Patch Size']}\")\n",
    "    print(f\"   Stride: {best_experiment['Stride']}\")\n",
    "    print(f\"   Threshold: {best_experiment['Best Threshold']}\")\n",
    "    print(f\"   IoU: {best_experiment['IoU']:.4f}\")\n",
    "    print(f\"   Lake Count Error: {best_experiment['Count Error']}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    plot_hyperparameter_results(\n",
    "        all_results, \n",
    "        save_path=os.path.join(config.output_dir, \"hyperparameter_comparison.png\")\n",
    "    )\n",
    "    \n",
    "    # Plot training history for best model\n",
    "    best_result = all_results[0]  # Assuming sorted by performance\n",
    "    plot_training_history(\n",
    "        best_result['training_history'],\n",
    "        save_path=os.path.join(config.output_dir, \"best_model_training_history.png\")\n",
    "    )\n",
    "    \n",
    "    print(f\"\\\\nüéâ Production pipeline completed successfully!\")\n",
    "    print(f\"   All results saved to: {config.output_dir}\")\n",
    "    \n",
    "    return all_results, summary_df\n",
    "\n",
    "print(f\"‚úÖ Main execution workflow defined\")\n",
    "print(f\"\\\\nüìã Ready to run! Execute the main() function to start the pipeline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Main Execution Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results visualization and analysis\n",
    "def plot_training_history(history, save_path=None):\n",
    "    \"\"\"Plot training and validation curves\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Validation Loss', color='red')\n",
    "    axes[0, 0].set_title('Training and Validation Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # IoU curve\n",
    "    axes[0, 1].plot(history['val_iou'], label='Validation IoU', color='green')\n",
    "    axes[0, 1].set_title('Validation IoU')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('IoU')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Accuracy curve\n",
    "    axes[1, 0].plot(history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "    axes[1, 0].set_title('Validation Accuracy')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Accuracy')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Combined metrics\n",
    "    axes[1, 1].plot(history['val_iou'], label='IoU', color='green')\n",
    "    axes[1, 1].plot(history['val_accuracy'], label='Accuracy', color='orange')\n",
    "    axes[1, 1].set_title('Validation Metrics')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Score')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Training curves saved: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_hyperparameter_results(all_results, save_path=None):\n",
    "    \"\"\"Plot comparison of hyperparameter experiments\"\"\"\n",
    "    if not all_results:\n",
    "        print(\"No results to plot\")\n",
    "        return\n",
    "    \n",
    "    # Extract data for plotting\n",
    "    experiments = []\n",
    "    ious = []\n",
    "    accuracies = []\n",
    "    lake_counts_error = []\n",
    "    \n",
    "    for result in all_results:\n",
    "        config = result['config']\n",
    "        metrics = result['final_metrics']\n",
    "        \n",
    "        experiment_label = f\"P{config['patch_size']}_S{config['stride']}_T{config['best_threshold']}\"\n",
    "        experiments.append(experiment_label)\n",
    "        ious.append(metrics['pixel_iou'])\n",
    "        accuracies.append(metrics['pixel_accuracy'])\n",
    "        lake_counts_error.append(metrics['object_metrics']['count_error'])\n",
    "    \n",
    "    # Create comparison plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # IoU comparison\n",
    "    axes[0, 0].bar(experiments, ious, color='skyblue')\n",
    "    axes[0, 0].set_title('IoU Comparison Across Experiments')\n",
    "    axes[0, 0].set_ylabel('IoU')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Accuracy comparison\n",
    "    axes[0, 1].bar(experiments, accuracies, color='lightgreen')\n",
    "    axes[0, 1].set_title('Accuracy Comparison Across Experiments')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Lake count error\n",
    "    axes[1, 0].bar(experiments, lake_counts_error, color='salmon')\n",
    "    axes[1, 0].set_title('Lake Count Error Across Experiments')\n",
    "    axes[1, 0].set_ylabel('Count Error')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Combined scatter plot\n",
    "    axes[1, 1].scatter(ious, accuracies, s=100, c=lake_counts_error, cmap='viridis')\n",
    "    for i, exp in enumerate(experiments):\n",
    "        axes[1, 1].annotate(exp, (ious[i], accuracies[i]), xytext=(5, 5), \n",
    "                           textcoords='offset points', fontsize=8)\n",
    "    axes[1, 1].set_xlabel('IoU')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].set_title('IoU vs Accuracy (Color = Count Error)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Hyperparameter comparison saved: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_results_summary(all_results):\n",
    "    \"\"\"Create summary table of all experiments\"\"\"\n",
    "    summary_data = []\n",
    "    \n",
    "    for result in all_results:\n",
    "        config = result['config']\n",
    "        metrics = result['final_metrics']\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Experiment': result['experiment_name'],\n",
    "            'Patch Size': config['patch_size'],\n",
    "            'Stride': config['stride'],\n",
    "            'Best Threshold': config['best_threshold'],\n",
    "            'IoU': metrics['pixel_iou'],\n",
    "            'Accuracy': metrics['pixel_accuracy'],\n",
    "            'True Lakes': metrics['object_metrics']['true_lake_count'],\n",
    "            'Pred Lakes': metrics['object_metrics']['pred_lake_count'],\n",
    "            'Count Error': metrics['object_metrics']['count_error'],\n",
    "            'Loading Test': result['loading_test_passed']\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Sort by IoU (best first)\n",
    "    df = df.sort_values('IoU', ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(f\"‚úÖ Results analysis and visualization system defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full image evaluation with boundary constraints\n",
    "def predict_full_image(model, image, boundary_mask, patch_size, stride):\n",
    "    \"\"\"Apply model to full image using sliding window with boundary constraints\"\"\"\n",
    "    model.eval()\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Initialize output arrays\n",
    "    full_mask = np.zeros((height, width), dtype=np.float32)\n",
    "    count_mask = np.zeros((height, width), dtype=np.float32)\n",
    "    \n",
    "    # Image preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    patches_processed = 0\n",
    "    patches_skipped = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(\n",
    "            range(0, height - patch_size + 1, stride),\n",
    "            desc=f\"Processing patches\"\n",
    "        )\n",
    "        \n",
    "        for y in pbar:\n",
    "            for x in range(0, width - patch_size + 1, stride):\n",
    "                # Check boundary constraint\n",
    "                center_y = y + patch_size // 2\n",
    "                center_x = x + patch_size // 2\n",
    "                \n",
    "                if boundary_mask[center_y, center_x] == 0:\n",
    "                    patches_skipped += 1\n",
    "                    continue\n",
    "                \n",
    "                # Extract and process patch\n",
    "                patch = image[y:y+patch_size, x:x+patch_size, :3]\n",
    "                \n",
    "                # Resize to 224x224 for DINOv3\n",
    "                patch_224 = cv2.resize(patch, (224, 224))\n",
    "                \n",
    "                # Transform and predict\n",
    "                patch_tensor = transform(patch_224).unsqueeze(0).to(device)\n",
    "                pred_224 = model(patch_tensor).squeeze().cpu().numpy()\n",
    "                \n",
    "                # Resize back to original patch size\n",
    "                pred_patch = cv2.resize(pred_224, (patch_size, patch_size))\n",
    "                \n",
    "                # Accumulate predictions\n",
    "                full_mask[y:y+patch_size, x:x+patch_size] += pred_patch\n",
    "                count_mask[y:y+patch_size, x:x+patch_size] += 1\n",
    "                \n",
    "                patches_processed += 1\n",
    "                \n",
    "                if patches_processed % 100 == 0:\n",
    "                    pbar.set_postfix({\n",
    "                        'processed': patches_processed,\n",
    "                        'skipped': patches_skipped\n",
    "                    })\n",
    "    \n",
    "    # Average overlapping predictions\n",
    "    final_mask = np.divide(\n",
    "        full_mask, count_mask, \n",
    "        out=np.zeros_like(full_mask), \n",
    "        where=count_mask!=0\n",
    "    )\n",
    "    \n",
    "    # Apply boundary constraint to final result\n",
    "    final_mask = final_mask * boundary_mask\n",
    "    \n",
    "    print(f\"   Processed {patches_processed} patches, skipped {patches_skipped}\")\n",
    "    \n",
    "    return final_mask\n",
    "\n",
    "\n",
    "def evaluate_full_image(model, image, mask, boundary_mask, config):\n",
    "    \"\"\"Evaluate model on full image with smart patch processing\"\"\"\n",
    "    print(f\"üñºÔ∏è Evaluating on full image...\")\n",
    "    \n",
    "    # Generate full image prediction\n",
    "    predicted_mask = predict_full_image(\n",
    "        model, image, boundary_mask, \n",
    "        config.current_patch_size, config.current_stride\n",
    "    )\n",
    "    \n",
    "    # Pixel-level metrics\n",
    "    pixel_iou, pixel_accuracy = calculate_metrics(\n",
    "        torch.from_numpy(predicted_mask).unsqueeze(0).unsqueeze(0),\n",
    "        torch.from_numpy(mask).unsqueeze(0).unsqueeze(0),\n",
    "        threshold=config.current_threshold\n",
    "    )\n",
    "    \n",
    "    # Object-based metrics\n",
    "    object_metrics = calculate_object_metrics(\n",
    "        predicted_mask, mask, threshold=config.current_threshold\n",
    "    )\n",
    "    \n",
    "    # Combined metrics\n",
    "    full_metrics = {\n",
    "        'pixel_iou': pixel_iou,\n",
    "        'pixel_accuracy': pixel_accuracy,\n",
    "        'object_metrics': object_metrics\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\\\nüìä Full Image Evaluation Results:\")\n",
    "    print(f\"   Pixel IoU: {pixel_iou:.4f}\")\n",
    "    print(f\"   Pixel Accuracy: {pixel_accuracy:.4f}\")\n",
    "    print_object_metrics(object_metrics)\n",
    "    \n",
    "    return full_metrics\n",
    "\n",
    "print(f\"‚úÖ Full image evaluation system defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Full Image Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter testing framework\n",
    "def test_probability_thresholds(model, val_loader, thresholds):\n",
    "    \"\"\"Test different probability thresholds on validation set\"\"\"\n",
    "    print(f\"üéØ Testing probability thresholds: {thresholds}\")\n",
    "    \n",
    "    # Get all predictions\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=\"Getting predictions\"):\n",
    "            images = images.to(device)\n",
    "            preds = model(images)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(masks)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    \n",
    "    # Test each threshold\n",
    "    threshold_results = {}\n",
    "    for threshold in thresholds:\n",
    "        iou, accuracy = calculate_metrics(all_preds, all_targets, threshold)\n",
    "        threshold_results[threshold] = {'iou': iou, 'accuracy': accuracy}\n",
    "        print(f\"   Threshold {threshold}: IoU={iou:.4f}, Accuracy={accuracy:.4f}\")\n",
    "    \n",
    "    return threshold_results\n",
    "\n",
    "\n",
    "def run_hyperparameter_experiment(image, mask, boundary_mask, config):\n",
    "    \"\"\"Run single experiment with current hyperparameters\"\"\"\n",
    "    experiment_name = config.get_experiment_name()\n",
    "    print(f\"\\\\nüî¨ Running experiment: {experiment_name}\")\n",
    "    \n",
    "    # Create datasets with current patch size\n",
    "    train_dataset, val_dataset = create_datasets(image, mask, boundary_mask, config)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "    \n",
    "    # Create and train model\n",
    "    model = DINOv3LakeDetector(\n",
    "        dinov3_model_name=config.dinov3_model,\n",
    "        feature_dim=config.dinov3_feature_dim\n",
    "    ).to(device)\n",
    "    \n",
    "    # Train model\n",
    "    trained_model, history = train_model_with_validation(model, train_loader, val_loader, config)\n",
    "    \n",
    "    # Test different probability thresholds\n",
    "    threshold_results = test_probability_thresholds(\n",
    "        trained_model, val_loader, config.probability_thresholds\n",
    "    )\n",
    "    \n",
    "    # Find best threshold\n",
    "    best_threshold = max(threshold_results.items(), key=lambda x: x[1]['iou'])[0]\n",
    "    config.current_threshold = best_threshold\n",
    "    \n",
    "    # Final evaluation with best threshold\n",
    "    final_metrics = evaluate_full_image(\n",
    "        trained_model, image, mask, boundary_mask, config\n",
    "    )\n",
    "    \n",
    "    # Combine all results\n",
    "    experiment_results = {\n",
    "        'experiment_name': experiment_name,\n",
    "        'config': {\n",
    "            'patch_size': config.current_patch_size,\n",
    "            'stride': config.current_stride,\n",
    "            'best_threshold': best_threshold\n",
    "        },\n",
    "        'training_history': history,\n",
    "        'threshold_results': threshold_results,\n",
    "        'final_metrics': final_metrics\n",
    "    }\n",
    "    \n",
    "    # Save model\n",
    "    model_path = save_model(trained_model, config, history, final_metrics, experiment_name)\n",
    "    \n",
    "    # Test model loading\n",
    "    test_input = next(iter(val_loader))[0][:1].to(device)  # Single sample for testing\n",
    "    loading_success = test_model_loading(trained_model, model_path, test_input)\n",
    "    experiment_results['loading_test_passed'] = loading_success\n",
    "    \n",
    "    return experiment_results\n",
    "\n",
    "\n",
    "def run_full_hyperparameter_search(image, mask, boundary_mask, config):\n",
    "    \"\"\"Run complete hyperparameter search across all combinations\"\"\"\n",
    "    print(f\"üîç Starting full hyperparameter search...\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Test all combinations of patch sizes and strides\n",
    "    for patch_size, stride in zip(config.patch_sizes, config.strides):\n",
    "        config.update_experiment(patch_size, stride)\n",
    "        \n",
    "        try:\n",
    "            results = run_hyperparameter_experiment(image, mask, boundary_mask, config)\n",
    "            all_results.append(results)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Experiment {config.get_experiment_name()} failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Save all results\n",
    "    results_path = os.path.join(config.output_dir, \"hyperparameter_search_results.json\")\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"‚úÖ Hyperparameter search complete. Results saved to: {results_path}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "print(f\"‚úÖ Hyperparameter testing framework defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Hyperparameter Testing Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust model saving and loading system\n",
    "def save_model(model, config, history, metrics, experiment_name):\n",
    "    \"\"\"Save model with all necessary information for inference\"\"\"\n",
    "    save_path = os.path.join(config.output_dir, f\"{experiment_name}.pth\")\n",
    "    \n",
    "    # Create comprehensive save package\n",
    "    save_package = {\n",
    "        # Model weights (state_dict approach for compatibility)\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        \n",
    "        # Model configuration\n",
    "        'model_config': {\n",
    "            'dinov3_model': config.dinov3_model,\n",
    "            'feature_dim': config.dinov3_feature_dim,\n",
    "            'patch_size': config.current_patch_size,\n",
    "            'stride': config.current_stride,\n",
    "            'threshold': config.current_threshold\n",
    "        },\n",
    "        \n",
    "        # Training information\n",
    "        'training_info': {\n",
    "            'num_epochs': config.num_epochs,\n",
    "            'learning_rate': config.learning_rate,\n",
    "            'batch_size': config.batch_size,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        },\n",
    "        \n",
    "        # Performance metrics\n",
    "        'metrics': metrics,\n",
    "        \n",
    "        # Training history\n",
    "        'history': history,\n",
    "        \n",
    "        # Data information\n",
    "        'data_info': {\n",
    "            'image_path': config.image_path,\n",
    "            'mask_path': config.mask_path,\n",
    "            'shapefile_path': config.shapefile_path\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save the package\n",
    "    torch.save(save_package, save_path)\n",
    "    print(f\"‚úÖ Model saved: {save_path}\")\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "\n",
    "def load_model(model_path, device='cpu'):\n",
    "    \"\"\"Load model and return model instance with configuration\"\"\"\n",
    "    print(f\"üìÇ Loading model from: {model_path}\")\n",
    "    \n",
    "    # Load the save package\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    # Recreate model architecture\n",
    "    model_config = checkpoint['model_config']\n",
    "    model = DINOv3LakeDetector(\n",
    "        dinov3_model_name=model_config['dinov3_model'],\n",
    "        feature_dim=model_config['feature_dim']\n",
    "    )\n",
    "    \n",
    "    # Load trained weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded successfully\")\n",
    "    print(f\"   Patch size: {model_config['patch_size']}\")\n",
    "    print(f\"   Stride: {model_config['stride']}\")\n",
    "    print(f\"   Threshold: {model_config['threshold']}\")\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "\n",
    "def test_model_loading(original_model, save_path, test_input):\n",
    "    \"\"\"Test that saved model loads correctly and produces same predictions\"\"\"\n",
    "    print(f\"üß™ Testing model loading...\")\n",
    "    \n",
    "    # Get prediction from original model\n",
    "    original_model.eval()\n",
    "    with torch.no_grad():\n",
    "        original_pred = original_model(test_input)\n",
    "    \n",
    "    # Load model and get prediction\n",
    "    loaded_model, _ = load_model(save_path, device=test_input.device)\n",
    "    with torch.no_grad():\n",
    "        loaded_pred = loaded_model(test_input)\n",
    "    \n",
    "    # Compare predictions\n",
    "    diff = torch.abs(original_pred - loaded_pred).max().item()\n",
    "    \n",
    "    if diff < 1e-6:\n",
    "        print(f\"‚úÖ Model loading test PASSED (max diff: {diff:.2e})\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"‚ùå Model loading test FAILED (max diff: {diff:.2e})\")\n",
    "        return False\n",
    "\n",
    "print(f\"‚úÖ Model saving/loading system defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Model Saving and Loading System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced object-based evaluation with scikit-image\n",
    "def calculate_object_metrics(pred_mask, true_mask, threshold=0.5):\n",
    "    \"\"\"Calculate object-based metrics: lake count, size distribution, etc.\"\"\"\n",
    "    from skimage.measure import label, regionprops\n",
    "    \n",
    "    # Convert to binary masks\n",
    "    pred_binary = (pred_mask > threshold).astype(np.uint8)\n",
    "    true_binary = (true_mask > 0).astype(np.uint8)\n",
    "    \n",
    "    # Find connected components (individual lakes)\n",
    "    pred_labeled = label(pred_binary)\n",
    "    true_labeled = label(true_binary)\n",
    "    \n",
    "    # Get properties of each lake\n",
    "    pred_props = regionprops(pred_labeled)\n",
    "    true_props = regionprops(true_labeled)\n",
    "    \n",
    "    # Extract lake sizes (areas)\n",
    "    pred_sizes = [prop.area for prop in pred_props]\n",
    "    true_sizes = [prop.area for prop in true_props]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'true_lake_count': len(true_sizes),\n",
    "        'pred_lake_count': len(pred_sizes),\n",
    "        'true_total_area': sum(true_sizes),\n",
    "        'pred_total_area': sum(pred_sizes),\n",
    "        'true_mean_size': np.mean(true_sizes) if true_sizes else 0,\n",
    "        'pred_mean_size': np.mean(pred_sizes) if pred_sizes else 0,\n",
    "        'true_max_size': max(true_sizes) if true_sizes else 0,\n",
    "        'pred_max_size': max(pred_sizes) if pred_sizes else 0,\n",
    "        'count_error': abs(len(pred_sizes) - len(true_sizes)),\n",
    "        'area_error': abs(sum(pred_sizes) - sum(true_sizes))\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_object_metrics(metrics):\n",
    "    \"\"\"Print object-based metrics in a readable format\"\"\"\n",
    "    print(f\"\\nüìä Object-Based Evaluation:\")\n",
    "    print(f\"   Lake Count - True: {metrics['true_lake_count']}, Predicted: {metrics['pred_lake_count']} (error: {metrics['count_error']})\")\n",
    "    print(f\"   Total Area - True: {metrics['true_total_area']}, Predicted: {metrics['pred_total_area']} (error: {metrics['area_error']})\")\n",
    "    print(f\"   Mean Size - True: {metrics['true_mean_size']:.1f}, Predicted: {metrics['pred_mean_size']:.1f}\")\n",
    "    print(f\"   Max Size - True: {metrics['true_max_size']}, Predicted: {metrics['pred_max_size']}\")\n",
    "\n",
    "print(f\"‚úÖ Enhanced object-based evaluation system defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Object-Based Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object-based evaluation (lake counting and size analysis)\n",
    "def calculate_object_metrics(pred_mask, true_mask, threshold=0.5):\n",
    "    \"\"\"Calculate object-based metrics: lake count, size distribution, etc.\"\"\"\n",
    "    from skimage.measure import label, regionprops\n",
    "    \n",
    "    # Convert to binary masks\n",
    "    pred_binary = (pred_mask > threshold).astype(np.uint8)\n",
    "    true_binary = (true_mask > 0).astype(np.uint8)\n",
    "    \n",
    "    # Find connected components (individual lakes)\n",
    "    pred_labeled = label(pred_binary)\n",
    "    true_labeled = label(true_binary)\n",
    "    \n",
    "    # Get properties of each lake\n",
    "    pred_props = regionprops(pred_labeled)\n",
    "    true_props = regionprops(true_labeled)\n",
    "    \n",
    "    # Extract lake sizes (areas)\n",
    "    pred_sizes = [prop.area for prop in pred_props]\n",
    "    true_sizes = [prop.area for prop in true_props]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'true_lake_count': len(true_sizes),\n",
    "        'pred_lake_count': len(pred_sizes),\n",
    "        'true_total_area': sum(true_sizes),\n",
    "        'pred_total_area': sum(pred_sizes),\n",
    "        'true_mean_size': np.mean(true_sizes) if true_sizes else 0,\n",
    "        'pred_mean_size': np.mean(pred_sizes) if pred_sizes else 0,\n",
    "        'true_max_size': max(true_sizes) if true_sizes else 0,\n",
    "        'pred_max_size': max(pred_sizes) if pred_sizes else 0,\n",
    "        'count_error': abs(len(pred_sizes) - len(true_sizes)),\n",
    "        'area_error': abs(sum(pred_sizes) - sum(true_sizes))\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_object_metrics(metrics):\n",
    "    \"\"\"Print object-based metrics in a readable format\"\"\"\n",
    "    print(f\"\\nüìä Object-Based Evaluation:\")\n",
    "    print(f\"   Lake Count - True: {metrics['true_lake_count']}, Predicted: {metrics['pred_lake_count']} (error: {metrics['count_error']})\")\n",
    "    print(f\"   Total Area - True: {metrics['true_total_area']}, Predicted: {metrics['pred_total_area']} (error: {metrics['area_error']})\")\n",
    "    print(f\"   Mean Size - True: {metrics['true_mean_size']:.1f}, Predicted: {metrics['pred_mean_size']:.1f}\")\n",
    "    print(f\"   Max Size - True: {metrics['true_max_size']}, Predicted: {metrics['pred_max_size']}\")\n",
    "\n",
    "print(f\"‚úÖ Object-based evaluation system defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DINOv3 + U-Net Lake Detection - Production Version\n",
    "\n",
    "## Overview\n",
    "This notebook trains a deep learning model for pixel-level glacial lake detection using:\n",
    "- **DINOv3**: Satellite-trained vision transformer as feature extractor (frozen)\n",
    "- **U-Net Decoder**: Trainable segmentation head for precise lake boundaries\n",
    "- **Smart Patch Strategy**: Small conceptual patches (16-32px) resized to 224px for DINOv3\n",
    "- **Boundary Constraints**: Training only within glacier areas from shapefiles\n",
    "\n",
    "## Key Features\n",
    "- Proper train/validation split with performance tracking\n",
    "- Hyperparameter testing (patch sizes, strides, thresholds)\n",
    "- Object-based evaluation metrics (lake counting)\n",
    "- Robust model saving/loading system\n",
    "- Production-ready code structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package installation for Google Colab\n",
    "!pip install torch torchvision transformers accelerate\n",
    "!pip install opencv-python pillow scikit-image\n",
    "!pip install numpy scipy scikit-learn\n",
    "!pip install rasterio geopandas fiona shapely\n",
    "!pip install matplotlib seaborn\n",
    "!pip install tqdm\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports - organized by functionality\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Computer vision and image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Geospatial processing\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio.features import geometry_mask\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# HuggingFace and DINOv3\n",
    "from transformers import AutoModel\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup device and random seeds for reproducibility\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"‚úÖ Device: {device}\")\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configuration System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration class for all hyperparameters\n",
    "class Config:\n",
    "    \"\"\"Configuration class for DINOv3 lake detection training\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # File paths\n",
    "        self.image_path = '/content/drive/MyDrive/superlakes/2021-09-04_fcc_testclip2.tif'\n",
    "        self.mask_path = '/content/drive/MyDrive/superlakes/lake_mask_testclip2.tif'\n",
    "        self.shapefile_path = '/content/drive/MyDrive/superlakes/vectors/clip_by_glacier.shp'\n",
    "        self.output_dir = '/content/drive/MyDrive/superlakes_production/'\n",
    "        \n",
    "        # HuggingFace model\n",
    "        self.hf_token = \"insert-hf-token-here\"\n",
    "        self.dinov3_model = \"facebook/dinov3-vitb16-pretrain-lvd1689m\"\n",
    "        \n",
    "        # Model architecture\n",
    "        self.dinov3_feature_dim = 768\n",
    "        self.dinov3_input_size = 224\n",
    "        \n",
    "        # Training parameters\n",
    "        self.batch_size = 4\n",
    "        self.num_epochs = 10\n",
    "        self.learning_rate = 0.001\n",
    "        self.val_split = 0.2\n",
    "        self.early_stopping_patience = 3\n",
    "        \n",
    "        # Dataset parameters\n",
    "        self.max_patches = 5000\n",
    "        self.lake_ratio = 0.7  # Ratio of lake patches to background patches\n",
    "        self.min_lake_coverage = 0.01  # Minimum lake coverage in patch (1%)\n",
    "        \n",
    "        # Hyperparameters to test\n",
    "        self.patch_sizes = [16, 20, 32]\n",
    "        self.strides = [8, 10, 16]  # Corresponding to patch sizes\n",
    "        self.probability_thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "        \n",
    "        # Current experiment settings (will be updated during hyperparameter search)\n",
    "        self.current_patch_size = 16\n",
    "        self.current_stride = 8\n",
    "        self.current_threshold = 0.5\n",
    "    \n",
    "    def update_experiment(self, patch_size, stride, threshold=0.5):\n",
    "        \"\"\"Update current experiment parameters\"\"\"\n",
    "        self.current_patch_size = patch_size\n",
    "        self.current_stride = stride\n",
    "        self.current_threshold = threshold\n",
    "    \n",
    "    def get_experiment_name(self):\n",
    "        \"\"\"Generate experiment name for saving results\"\"\"\n",
    "        return f\"dinov3_patch{self.current_patch_size}_stride{self.current_stride}_thr{self.current_threshold}\"\n",
    "    \n",
    "    def save_config(self, filepath):\n",
    "        \"\"\"Save configuration to JSON file\"\"\"\n",
    "        config_dict = {k: v for k, v in self.__dict__.items() if not k.startswith('hf_token')}\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(config_dict, f, indent=2, default=str)\n",
    "        print(f\"‚úÖ Configuration saved to {filepath}\")\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "print(f\"‚úÖ Configuration initialized\")\n",
    "print(f\"   Current experiment: {config.get_experiment_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Google Drive Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and authenticate with HuggingFace\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Authenticate with HuggingFace for DINOv3 access\n",
    "login(token=config.hf_token)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "print(f\"‚úÖ Output directory: {config.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load satellite image and manual lake mask\n",
    "def load_data(image_path, mask_path):\n",
    "    \"\"\"Load satellite image and ground truth mask\"\"\"\n",
    "    print(f\"üìÇ Loading data...\")\n",
    "    \n",
    "    # Load satellite image\n",
    "    with rasterio.open(image_path) as src:\n",
    "        image = src.read()  # Shape: (channels, height, width)\n",
    "        image = np.transpose(image, (1, 2, 0))  # Convert to (height, width, channels)\n",
    "        image_profile = src.profile.copy()\n",
    "    \n",
    "    # Load ground truth mask\n",
    "    with rasterio.open(mask_path) as src:\n",
    "        mask = src.read(1)  # Read first band\n",
    "    \n",
    "    # Convert to appropriate formats\n",
    "    image_rgb = image[:,:,:3].astype(np.uint8)  # Use only RGB channels\n",
    "    mask_binary = (mask > 0).astype(np.float32)  # Binary mask for training\n",
    "    \n",
    "    print(f\"   Image shape: {image_rgb.shape}\")\n",
    "    print(f\"   Mask shape: {mask_binary.shape}\")\n",
    "    print(f\"   Image value range: {image_rgb.min()} - {image_rgb.max()}\")\n",
    "    print(f\"   Lake pixels: {mask_binary.sum():,.0f} ({mask_binary.mean()*100:.2f}%)\")\n",
    "    \n",
    "    return image_rgb, mask_binary, image_profile\n",
    "\n",
    "# Load the data\n",
    "image_rgb, mask_binary, image_profile = load_data(config.image_path, config.mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Boundary Mask Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boundary mask from glacier shapefile\n",
    "def create_boundary_mask(image_path, shapefile_path):\n",
    "    \"\"\"Create binary mask from shapefile to constrain analysis to glacier areas\"\"\"\n",
    "    print(f\"üó∫Ô∏è Creating boundary mask from shapefile...\")\n",
    "    \n",
    "    # Load shapefile\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    print(f\"   Loaded {len(gdf)} polygon(s) from shapefile\")\n",
    "    \n",
    "    # Get image spatial information\n",
    "    with rasterio.open(image_path) as src:\n",
    "        transform = src.transform\n",
    "        shape = src.shape\n",
    "        crs = src.crs\n",
    "    \n",
    "    print(f\"   Image CRS: {crs}\")\n",
    "    print(f\"   Shapefile CRS: {gdf.crs}\")\n",
    "    \n",
    "    # Reproject shapefile to match image CRS if needed\n",
    "    if gdf.crs != crs:\n",
    "        print(f\"   Reprojecting shapefile from {gdf.crs} to {crs}\")\n",
    "        gdf = gdf.to_crs(crs)\n",
    "    \n",
    "    # Create binary mask (True inside polygons, False outside)\n",
    "    boundary_mask = ~geometry_mask(\n",
    "        gdf.geometry, \n",
    "        transform=transform, \n",
    "        invert=False, \n",
    "        out_shape=shape\n",
    "    )\n",
    "    \n",
    "    pixels_inside = boundary_mask.sum()\n",
    "    percentage_inside = pixels_inside / boundary_mask.size * 100\n",
    "    \n",
    "    print(f\"   Boundary mask created: {pixels_inside:,} pixels inside ({percentage_inside:.1f}%)\")\n",
    "    \n",
    "    return boundary_mask.astype(np.uint8)\n",
    "\n",
    "# Create boundary mask\n",
    "boundary_mask = create_boundary_mask(config.image_path, config.shapefile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net Decoder for pixel-level segmentation\n",
    "class UNetDecoder(nn.Module):\n",
    "    \"\"\"U-Net decoder that converts DINOv3 features to segmentation masks\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_dim=768, target_size=224):\n",
    "        super(UNetDecoder, self).__init__()\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # Progressive upsampling layers\n",
    "        self.conv1 = nn.Conv2d(feature_dim, 512, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.final_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with ReLU activation\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.final_conv(x)\n",
    "        \n",
    "        # Ensure output is exactly the target size\n",
    "        x = nn.functional.interpolate(\n",
    "            x, size=(self.target_size, self.target_size), \n",
    "            mode='bilinear', align_corners=False\n",
    "        )\n",
    "        \n",
    "        # Apply sigmoid for probability output\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Complete DINOv3 + U-Net model\n",
    "class DINOv3LakeDetector(nn.Module):\n",
    "    \"\"\"Complete model: DINOv3 feature extractor + U-Net decoder for lake segmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, dinov3_model_name, feature_dim=768):\n",
    "        super(DINOv3LakeDetector, self).__init__()\n",
    "        \n",
    "        # Load pre-trained DINOv3 model (frozen for feature extraction)\n",
    "        self.dinov3 = AutoModel.from_pretrained(dinov3_model_name)\n",
    "        \n",
    "        # Freeze DINOv3 parameters (use as feature extractor only)\n",
    "        for param in self.dinov3.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Trainable U-Net decoder\n",
    "        self.decoder = UNetDecoder(feature_dim=feature_dim, target_size=224)\n",
    "        \n",
    "        print(f\"‚úÖ Model created: DINOv3 (frozen) + U-Net decoder (trainable)\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features with DINOv3 (no gradients)\n",
    "        with torch.no_grad():\n",
    "            features = self.dinov3(x).last_hidden_state\n",
    "            \n",
    "            # Remove CLS token and reshape to spatial feature map\n",
    "            patch_features = features[:, 1:]  # Remove first token (CLS)\n",
    "            batch_size, num_patches, feature_dim = patch_features.shape\n",
    "            \n",
    "            # Calculate spatial dimensions (assume square patches)\n",
    "            spatial_size = int(num_patches ** 0.5)\n",
    "            \n",
    "            # Reshape to 2D feature map\n",
    "            feature_map = patch_features.reshape(\n",
    "                batch_size, spatial_size, spatial_size, feature_dim\n",
    "            )\n",
    "            feature_map = feature_map.permute(0, 3, 1, 2)  # (B, C, H, W)\n",
    "        \n",
    "        # Generate segmentation mask with trainable decoder\n",
    "        mask = self.decoder(feature_map)\n",
    "        return mask\n",
    "\n",
    "print(f\"‚úÖ Model architecture defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Dataset Creation with Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class for boundary-constrained lake detection\n",
    "class LakeDetectionDataset(Dataset):\n",
    "    \"\"\"Dataset that samples patches only inside glacier boundaries\"\"\"\n",
    "    \n",
    "    def __init__(self, image, mask, boundary_mask, patch_size, max_patches, lake_ratio):\n",
    "        self.patch_size = patch_size\n",
    "        self.dinov3_size = 224\n",
    "        self.patches = []\n",
    "        self.mask_patches = []\n",
    "        \n",
    "        # Data transforms for DINOv3 (ImageNet normalization)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        self._create_patches(image, mask, boundary_mask, max_patches, lake_ratio)\n",
    "    \n",
    "    def _create_patches(self, image, mask, boundary_mask, max_patches, lake_ratio):\n",
    "        \"\"\"Extract patches from image constrained by boundary mask\"\"\"\n",
    "        height, width = image.shape[:2]\n",
    "        stride = self.patch_size // 8  # Dense sampling for better coverage\n",
    "        \n",
    "        print(f\"   Creating {self.patch_size}x{self.patch_size} patches with stride {stride}...\")\n",
    "        \n",
    "        lake_patches = []\n",
    "        background_patches = []\n",
    "        \n",
    "        # Sample patches within boundary\n",
    "        for y in range(0, height - self.patch_size + 1, stride):\n",
    "            for x in range(0, width - self.patch_size + 1, stride):\n",
    "                # Check if patch center is inside boundary\n",
    "                center_y = y + self.patch_size // 2\n",
    "                center_x = x + self.patch_size // 2\n",
    "                \n",
    "                if boundary_mask[center_y, center_x]:\n",
    "                    # Calculate lake coverage in this patch\n",
    "                    mask_patch = mask[y:y+self.patch_size, x:x+self.patch_size]\n",
    "                    lake_coverage = mask_patch.mean()\n",
    "                    \n",
    "                    patch_info = {\n",
    "                        'y': y, 'x': x, 'coverage': lake_coverage\n",
    "                    }\n",
    "                    \n",
    "                    if lake_coverage > config.min_lake_coverage:\n",
    "                        lake_patches.append(patch_info)\n",
    "                    elif lake_coverage == 0:\n",
    "                        background_patches.append(patch_info)\n",
    "        \n",
    "        print(f\"   Found {len(lake_patches)} lake patches, {len(background_patches)} background patches\")\n",
    "        \n",
    "        # Create balanced dataset\n",
    "        n_lake = min(len(lake_patches), int(max_patches * lake_ratio))\n",
    "        n_background = min(len(background_patches), max_patches - n_lake)\n",
    "        \n",
    "        print(f\"   Selecting {n_lake} lake patches and {n_background} background patches\")\n",
    "        \n",
    "        # Sort lake patches by coverage (highest first) and select top ones\n",
    "        lake_patches.sort(key=lambda x: x['coverage'], reverse=True)\n",
    "        selected_patches = lake_patches[:n_lake] + np.random.choice(\n",
    "            background_patches, n_background, replace=False\n",
    "        ).tolist()\n",
    "        \n",
    "        # Extract actual image and mask patches\n",
    "        for patch_info in selected_patches:\n",
    "            y, x = patch_info['y'], patch_info['x']\n",
    "            \n",
    "            img_patch = image[y:y+self.patch_size, x:x+self.patch_size, :3]\n",
    "            mask_patch = mask[y:y+self.patch_size, x:x+self.patch_size]\n",
    "            \n",
    "            self.patches.append(img_patch)\n",
    "            self.mask_patches.append(mask_patch)\n",
    "        \n",
    "        print(f\"   Final dataset: {len(self.patches)} patches\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get patch and resize to DINOv3 input size\n",
    "        image_patch = self.patches[idx]\n",
    "        mask_patch = self.mask_patches[idx]\n",
    "        \n",
    "        # Resize to 224x224 for DINOv3\n",
    "        image_224 = cv2.resize(image_patch, (self.dinov3_size, self.dinov3_size))\n",
    "        mask_224 = cv2.resize(mask_patch.astype(np.float32), (self.dinov3_size, self.dinov3_size))\n",
    "        \n",
    "        # Apply transforms\n",
    "        image_tensor = self.transform(image_224)\n",
    "        mask_tensor = torch.from_numpy(mask_224).float().unsqueeze(0)\n",
    "        \n",
    "        return image_tensor, mask_tensor\n",
    "\n",
    "\n",
    "# Create dataset and split into train/validation\n",
    "def create_datasets(image, mask, boundary_mask, config):\n",
    "    \"\"\"Create train and validation datasets with proper split\"\"\"\n",
    "    print(f\"üìä Creating datasets...\")\n",
    "    \n",
    "    # Create full dataset\n",
    "    full_dataset = LakeDetectionDataset(\n",
    "        image, mask, boundary_mask,\n",
    "        patch_size=config.current_patch_size,\n",
    "        max_patches=config.max_patches,\n",
    "        lake_ratio=config.lake_ratio\n",
    "    )\n",
    "    \n",
    "    # Split into train and validation\n",
    "    dataset_size = len(full_dataset)\n",
    "    val_size = int(dataset_size * config.val_split)\n",
    "    train_size = dataset_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    print(f\"   Train set: {len(train_dataset)} patches\")\n",
    "    print(f\"   Validation set: {len(val_dataset)} patches\")\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "print(f\"‚úÖ Dataset creation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Training System with Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with proper validation\n",
    "def train_model_with_validation(model, train_loader, val_loader, config):\n",
    "    \"\"\"Train model with validation tracking and early stopping\"\"\"\n",
    "    print(f\"üöÄ Starting training with validation...\")\n",
    "    \n",
    "    # Setup training components\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.decoder.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    # Training history tracking\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_iou': [],\n",
    "        'val_accuracy': []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(config.num_epochs):\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{config.num_epochs} ---\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f\"Training\")\n",
    "        for batch_idx, (images, masks) in enumerate(train_pbar):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix({'loss': loss.item():.4f})\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_val_preds = []\n",
    "        all_val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f\"Validation\")\n",
    "            for images, masks in val_pbar:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Collect predictions for metrics\n",
    "                all_val_preds.append(outputs.cpu())\n",
    "                all_val_targets.append(masks.cpu())\n",
    "                \n",
    "                val_pbar.set_postfix({'loss': loss.item():.4f})\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        val_preds = torch.cat(all_val_preds, dim=0)\n",
    "        val_targets = torch.cat(all_val_targets, dim=0)\n",
    "        \n",
    "        val_iou, val_accuracy = calculate_metrics(val_preds, val_targets, threshold=0.5)\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_iou'].append(val_iou)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        \n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"Val IoU: {val_iou:.4f}\")\n",
    "        print(f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"‚úÖ New best validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"‚è≥ Patience: {patience_counter}/{config.early_stopping_patience}\")\n",
    "            \n",
    "            if patience_counter >= config.early_stopping_patience:\n",
    "                print(f\"üõë Early stopping triggered\")\n",
    "                break\n",
    "    \n",
    "    # Load best model state\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"‚úÖ Loaded best model (val_loss: {best_val_loss:.4f})\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "# Evaluation metrics calculation\n",
    "def calculate_metrics(pred_masks, true_masks, threshold=0.5):\n",
    "    \"\"\"Calculate IoU and pixel accuracy metrics\"\"\"\n",
    "    pred_binary = (pred_masks > threshold).float()\n",
    "    \n",
    "    # IoU calculation\n",
    "    intersection = (pred_binary * true_masks).sum()\n",
    "    union = pred_binary.sum() + true_masks.sum() - intersection\n",
    "    iou = intersection / (union + 1e-8)\n",
    "    \n",
    "    # Pixel accuracy\n",
    "    accuracy = (pred_binary == true_masks).float().mean()\n",
    "    \n",
    "    return iou.item(), accuracy.item()\n",
    "\n",
    "print(f\"‚úÖ Training system defined\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
